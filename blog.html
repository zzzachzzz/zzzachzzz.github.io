<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Web Dev Blog - zzzachzzz</title><meta name="description" content="JavaScript, TypeScript, and React by example with code."/><meta name="next-head-count" content="4"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/069ff64b07ed1af4.css" as="style"/><link rel="stylesheet" href="/_next/static/css/069ff64b07ed1af4.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-eae37baa130ab03a.js" defer=""></script><script src="/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/_next/static/chunks/main-9d21f2f92d74d34f.js" defer=""></script><script src="/_next/static/chunks/pages/_app-0f31e0da3388de53.js" defer=""></script><script src="/_next/static/chunks/792-95b7cdfb484c5ddc.js" defer=""></script><script src="/_next/static/chunks/519-8d8f13e00821d3ab.js" defer=""></script><script src="/_next/static/chunks/pages/blog-aecbd0ff41c875d5.js" defer=""></script><script src="/_next/static/GUVWFM4qDg1OQBmqApV-Q/_buildManifest.js" defer=""></script><script src="/_next/static/GUVWFM4qDg1OQBmqApV-Q/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.5">html{font-size:16px;min-height:100vh;}/*!sc*/
html,body{height:100%;margin:0;padding:0;}/*!sc*/
@media only screen and (max-device-width:480px){html{font-size:14px;}}/*!sc*/
body{background-color:#3e4d4f;color:white;font-family: -apple-system,BlinkMacSystemFont,"Segoe UI","Roboto","Oxygen","Ubuntu","Cantarell","Fira Sans","Droid Sans","Helvetica Neue",sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;}/*!sc*/
*{box-sizing:border-box;}/*!sc*/
h1,h2,h3,h4,h5,h6{font-weight:400;}/*!sc*/
code,code[class*="language-"]{font-family: 'Inconsolata',Consolas,Monaco,'Andale Mono','Ubuntu Mono',monospace;}/*!sc*/
data-styled.g1[id="sc-global-bLrfTZ1"]{content:"sc-global-bLrfTZ1,"}/*!sc*/
.oXjRv{background-color:#272822;padding:0.2em 0.4em;font-size:0.8em;border-radius:0.3em;color:#ae81ff;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
data-styled.g2[id="A__A_-sc-14fqd0c-0"]{content:"oXjRv,"}/*!sc*/
.hxcnSJ{height:1.534rem;width:1.534rem;padding:0.2em;margin-left:5px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.hxcnSJ:hover > svg{stroke:#ae81ff;}/*!sc*/
data-styled.g3[id="RssLink___RssLink-sc-lk2wz-0"]{content:"hxcnSJ,"}/*!sc*/
.cbPkmK{height:100%;}/*!sc*/
data-styled.g4[id="RssLink___StyledSvg-sc-lk2wz-1"]{content:"cbPkmK,"}/*!sc*/
.lgEcag{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;font-size:1.2rem;margin:5px;}/*!sc*/
data-styled.g5[id="Navigation__Container-sc-10fffhi-0"]{content:"lgEcag,"}/*!sc*/
.bISkVn{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-text-decoration:none;text-decoration:none;gap:5px;}/*!sc*/
data-styled.g6[id="Navigation__Nav-sc-10fffhi-1"]{content:"bISkVn,"}/*!sc*/
.ECCqO{color:white;font-weight:500;line-height:1;}/*!sc*/
data-styled.g7[id="Navigation___StyledSpan-sc-10fffhi-2"]{content:"ECCqO,"}/*!sc*/
.fRlBcp{background-color:#272822;padding:0.2em 0.4em;font-size:0.8em;border-radius:0.3em;}/*!sc*/
data-styled.g8[id="Code-sc-1amjnp4-0"]{content:"fRlBcp,"}/*!sc*/
.cTrNrc{margin-left:auto !important;margin-right:auto !important;}/*!sc*/
data-styled.g9[id="TreeToJSX__Pre-sc-1taxolb-0"]{content:"cTrNrc,"}/*!sc*/
.bkGieB{color:#aaa;font-style:italic;border-left:2px solid #ddd;margin-left:0;margin-right:0;padding-left:10px;}/*!sc*/
data-styled.g10[id="TreeToJSX__BlockQuote-sc-1taxolb-1"]{content:"bkGieB,"}/*!sc*/
.gacNJW > p{margin:0;}/*!sc*/
data-styled.g11[id="TreeToJSX__Li-sc-1taxolb-2"]{content:"gacNJW,"}/*!sc*/
.epTijp{width:100%;height:100%;object-fit:contain;display:block;}/*!sc*/
data-styled.g12[id="TreeToJSX__Img-sc-1taxolb-3"]{content:"epTijp,"}/*!sc*/
.gjkXwZ{font-size:1.2em;line-height:1.4em;-webkit-letter-spacing:0.01em;-moz-letter-spacing:0.01em;-ms-letter-spacing:0.01em;letter-spacing:0.01em;overflow-wrap:break-word;padding:1.1em;margin:0 auto;}/*!sc*/
.gjkXwZ > *:not(pre){max-width:850px;margin-left:auto;margin-right:auto;}/*!sc*/
.gjkXwZ > pre{width:90vw;max-width:1100px;}/*!sc*/
data-styled.g13[id="BlogContent__Container-sc-10yyr2o-0"]{content:"gjkXwZ,"}/*!sc*/
.iUHJLk{height:300px;overflow:hidden;font-size:0.8rem;position:relative;}/*!sc*/
data-styled.g14[id="blog__ContentPreview-sc-gs9s1w-0"]{content:"iUHJLk,"}/*!sc*/
.jqumEm{position:absolute;bottom:0;box-shadow:0px 0px 10px 10px #3e4d4f;width:100%;}/*!sc*/
data-styled.g15[id="blog__Shadow-sc-gs9s1w-1"]{content:"jqumEm,"}/*!sc*/
.bbVJcj{border-radius:0.3em;border:3px solid #919191;-webkit-transition:border-color 0.3s;transition:border-color 0.3s;padding:0.2em;cursor:pointer;margin:1.5rem;}/*!sc*/
.bbVJcj:hover{border-color:#ae81ff;}/*!sc*/
.bbVJcj:hover a{color:#ae81ff;opacity:1;}/*!sc*/
.bbVJcj:not(:hover) header a{background:transparent;}/*!sc*/
data-styled.g16[id="blog__Article-sc-gs9s1w-2"]{content:"bbVJcj,"}/*!sc*/
.jaiTdr{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
data-styled.g17[id="blog__Header-sc-gs9s1w-3"]{content:"jaiTdr,"}/*!sc*/
.kZIFNj{text-align:center;}/*!sc*/
data-styled.g18[id="blog___StyledHeader-sc-gs9s1w-4"]{content:"kZIFNj,"}/*!sc*/
.gQnMzW{-webkit-text-decoration:none;text-decoration:none;color:white;}/*!sc*/
data-styled.g19[id="blog__BlogLink-sc-gs9s1w-5"]{content:"gQnMzW,"}/*!sc*/
.ckcSPp{display:block;text-align:center;margin:0 auto;width:-webkit-min-content;width:-moz-min-content;width:min-content;white-space:nowrap;opacity:0;-webkit-transition:opacity 0.3s,color 0.3s;transition:opacity 0.3s,color 0.3s;}/*!sc*/
data-styled.g20[id="blog___StyledBlogLink2-sc-gs9s1w-6"]{content:"ckcSPp,"}/*!sc*/
.iAkVvE{padding:0.7em 2em;margin:0 auto;-webkit-transition:background 0.3s,color 0.3s;transition:background 0.3s,color 0.3s;}/*!sc*/
data-styled.g21[id="blog___StyledBlogLink-sc-gs9s1w-7"]{content:"iAkVvE,"}/*!sc*/
.kRVzWU{text-align:center;}/*!sc*/
data-styled.g22[id="blog___StyledH-sc-gs9s1w-8"]{content:"kRVzWU,"}/*!sc*/
.hgLQfg{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;max-width:1200px;margin:0 auto;}/*!sc*/
data-styled.g23[id="blog___StyledDiv-sc-gs9s1w-9"]{content:"hgLQfg,"}/*!sc*/
.hxRHcf{margin-bottom:0.4em;}/*!sc*/
data-styled.g24[id="blog___StyledH2-sc-gs9s1w-10"]{content:"hxRHcf,"}/*!sc*/
.eaEZEq{font-size:0.8em;}/*!sc*/
data-styled.g25[id="blog___StyledTime-sc-gs9s1w-11"]{content:"eaEZEq,"}/*!sc*/
</style><style data-href="https://fonts.googleapis.com/css2?family=Inconsolata&display=swap">@font-face{font-family:'Inconsolata';font-style:normal;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=QldgNThLqRwH-OJ1UHjlKENVzkWGVkL3GZQmAwLYxYWI2qfdm7Lpp4U8aRk&skey=20fa6569a31c71ee&v=v37) format('woff')}@font-face{font-family:'Inconsolata';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=QldgNThLqRwH-OJ1UHjlKENVzkWGVkL3GZQmAwLYxYWI2qfdm7Lpp4U8WRL2kXWdycuJDETf&skey=20fa6569a31c71ee&v=v37) format('woff');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inconsolata';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=QldgNThLqRwH-OJ1UHjlKENVzkWGVkL3GZQmAwLYxYWI2qfdm7Lpp4U8WRP2kXWdycuJDETf&skey=20fa6569a31c71ee&v=v37) format('woff');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inconsolata';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=QldgNThLqRwH-OJ1UHjlKENVzkWGVkL3GZQmAwLYxYWI2qfdm7Lpp4U8WR32kXWdycuJDA&skey=20fa6569a31c71ee&v=v37) format('woff');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><div><div class="Navigation__Container-sc-10fffhi-0 lgEcag"><nav class="Navigation__Nav-sc-10fffhi-1 bISkVn"><a href="/" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">/</a><span class="Navigation___StyledSpan-sc-10fffhi-2 ECCqO">&gt;</span><a href="/blog" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">blog</a></nav><a href="/blog/rss.xml" target="_blank" rel="noopener noreferrer" title="RSS Feed" class="A__A_-sc-14fqd0c-0 oXjRv RssLink___RssLink-sc-lk2wz-0 hxcnSJ"><svg xmlns="http://www.w3.org/2000/svg" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round" class="RssLink___StyledSvg-sc-lk2wz-1 cbPkmK"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><circle cx="5" cy="19" r="1"></circle><path d="M4 4a16 16 0 0 1 16 16"></path><path d="M4 11a9 9 0 0 1 9 9"></path></svg></a></div><h1 class="blog___StyledH-sc-gs9s1w-8 kRVzWU">Recent Posts</h1><div class="blog___StyledDiv-sc-gs9s1w-9 hgLQfg"><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/hitting-a-target-file-size-with-ffmpeg-perfect-for-discord-clips" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Hitting a Target File Size With FFmpeg (Perfect for Discord Clips)</h2><time dateTime="2025-12-10T12:43:16.627Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">December 10, 2025</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>If you&#x27;ve ever tried to send a gaming clip over Discord as a free user, you&#x27;ve run into the 10MB upload limit. My process before creating this script was to use a collection of other ffmpeg commands to trial-and-error trimming the clip, and lowering the quality until it finally went below the 10MB threshold.</p><p>I wanted a way to say: <b>&quot;Here&#x27;s my clip. Make it 10MB. Do what you must.&quot;</b></p><p>So I wrote a Bash function that uses FFmpeg&#x27;s 2‑pass encoding method to reliably target a specific file size. It also has quality‑of‑life options for trimming timestamps. As you&#x27;ll see below, you can write other bash functions which call the main function to make this process happen by typing just a few characters into your terminal.</p><p>My setup:</p><ul><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Gaming on Windows, running the script in WSL (Git Bash will work too)</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Shadowplay 1 minute instant replay saved videos</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Discord 10MB file upload limit (non-Nitro paid users)</p></li></ul></div></div><a href="/blog/hitting-a-target-file-size-with-ffmpeg-perfect-for-discord-clips" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/accessing-a-dual-boot-linux-install-in-wsl-with-chroot" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Accessing a dual boot Linux install in WSL with chroot</h2><time dateTime="2024-10-11T14:49:56.465Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">October 11, 2024</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>Got a Windows &amp; Linux dual boot setup? Rather than setting up a new WSL install, wouldn&#x27;t it be nice to be able to &quot;import&quot; your existing native Linux install into WSL? While this method is not exactly an import, it is functionally similar.</p><h2 id="mounting-the-disk-partition">Mounting the disk partition</h2><p>Resources</p><ul><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p><a href="https://learn.microsoft.com/en-us/windows/wsl/wsl2-mount-disk#mounting-a-partitioned-disk" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">WSL 2 - Mounting a partitioned disk</a></p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p><a href="https://www.youtube.com/watch?v=aX1vH1j7m7U" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">EXT4 in Windows - Chris Titus Tech</a></p></li></ul><p>The first step is mounting the partition containing your Linux install. If you only want to access the files of an ext4 partition from Windows, you&#x27;ll only need this step.</p></div></div><a href="/blog/accessing-a-dual-boot-linux-install-in-wsl-with-chroot" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/how-to-change-a-pacman-packages-dependencies-on-arch-linux-with-remakepkg" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">How to Change a Pacman Package&#x27;s Dependencies on Arch Linux with remakepkg</h2><time dateTime="2022-10-22T20:13:29.318Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">October 22, 2022</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>Recently I ran into a dependency conflict after an update of a particular package, <a href="https://archlinux.org/packages/community/any/bitwarden-cli/" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">bitwarden-cli</a>. Prior to version 2022.6.2-2, <code class="Code-sc-1amjnp4-0 fRlBcp">bitwarden-cli</code> depended on <code class="Code-sc-1amjnp4-0 fRlBcp">nodejs</code>. It was in version 2022.6.2-2 that the dependency was changed from <code class="Code-sc-1amjnp4-0 fRlBcp">nodejs</code> to <code class="Code-sc-1amjnp4-0 fRlBcp">nodejs-lts-gallium</code>.</p><p>Okay, so what&#x27;s the big deal? The big deal is that <code class="Code-sc-1amjnp4-0 fRlBcp">nodejs</code> and <code class="Code-sc-1amjnp4-0 fRlBcp">nodejs-lts-gallium</code> cannot both be installed, as they&#x27;re listed as conflicting packages of one another (see the <b>Conflicts</b> section of <a href="https://archlinux.org/packages/community/x86_64/nodejs-lts-gallium/" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">nodejs-lts-gallium</a>). While I could have just gone ahead and removed <code class="Code-sc-1amjnp4-0 fRlBcp">nodejs</code> in favor of <code class="Code-sc-1amjnp4-0 fRlBcp">nodejs-lts-gallium</code>, I didn&#x27;t really want to, as I had no issues with it and wanted the latest version of <code class="Code-sc-1amjnp4-0 fRlBcp">nodejs</code>. And yes, alternatively I could have installed the latest version via <a href="https://github.com/nvm-sh/nvm" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">nvm</a> or otherwise, and kept <code class="Code-sc-1amjnp4-0 fRlBcp">nodejs-lts-gallium</code> (version 16.x at the time of this writing) as the system dependency.</p><p>For whatever your personal reasons are, you may wish to remove or alter the restrictions defined for a package by a package maintainer. In my case, I was able to figure out why the dependency change occurred in the first place. It was due to <a href="https://bugs.archlinux.org/task/74929" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">this bug</a>, a bug which affected a premium feature of Bitwarden that I didn&#x27;t even have access to. With this in mind, I felt comfortable discarding the new requirement of using <code class="Code-sc-1amjnp4-0 fRlBcp">nodejs-lts-gallium</code>.</p><p><b>IMPORTANT NOTE</b><br/>In writing this, I realized that <code class="Code-sc-1amjnp4-0 fRlBcp">--assume-installed nodejs-lts-gallium</code> solves my problem, without the need for <code class="Code-sc-1amjnp4-0 fRlBcp">remakepkg</code>. I just need to include that option during an upgrade, whenever there is a newer version of <code class="Code-sc-1amjnp4-0 fRlBcp">bitwarden-cli</code> available. This works when dealing with the absence of a package. However, <code class="Code-sc-1amjnp4-0 fRlBcp">remakepkg</code> may be needed for other scenarios. I&#x27;ll proceed with how I used <code class="Code-sc-1amjnp4-0 fRlBcp">remakepkg</code> to solve my problem.</p><p>So, how does one go about &quot;changing&quot; a package&#x27;s dependency? It&#x27;s done with the help of an AUR package, <a href="https://aur.archlinux.org/packages/remakepkg" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">remakepkg</a>. You can also find the git repo containing the script <a href="https://gitlab.com/ayekat/pacman-hacks" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">here</a>.</p></div></div><a href="/blog/how-to-change-a-pacman-packages-dependencies-on-arch-linux-with-remakepkg" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/a-curl-helper-function-for-easy-api-testing" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">A Curl Helper Function for Easy API Testing</h2><time dateTime="2021-09-06T18:23:42.735Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">September 6, 2021</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>I tend to prefer command line tools for development, in this case choosing <code class="Code-sc-1amjnp4-0 fRlBcp">curl</code> over Postman. Depending on the API that requests are being made to, curl commands can get out of hand, requiring numerous headers and other options to be manually attached on each request. The solution? Create a Bash helper function for curl, making our commands short and efficient.</p><p>The helper function:</p><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-bash" tabindex="0"><code class="language-bash"><span class="token keyword">function</span> <span class="token function-name function">curls</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token builtin class-name">local</span> response_code_and_method
  <span class="token assign-left variable">response_code_and_method</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token function">curl</span> <span class="token punctuation">\</span>
    --no-progress-meter <span class="token punctuation">\</span>
    --write-out <span class="token string">"%{response_code} %{method}"</span> <span class="token punctuation">\</span>
    --output /tmp/curls_body <span class="token punctuation">\</span>
    --header <span class="token string">"Content-Type: application/json"</span> <span class="token punctuation">\</span>
    $<span class="token punctuation">{</span>CURL_OPTIONS<span class="token punctuation">[</span>@<span class="token punctuation">]</span><span class="token punctuation">}</span> <span class="token punctuation">\</span>
    $CURL_BASE_URL/$@
  <span class="token variable">)</span></span>

  <span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token variable">$?</span> -eq <span class="token number">0</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>
    <span class="token builtin class-name">local</span> pretty_json
    <span class="token assign-left variable">pretty_json</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span>jq --color-output <span class="token string">'.'</span> /tmp/curls_body <span class="token operator"><span class="token file-descriptor important">2</span>></span> /dev/null<span class="token variable">)</span></span>
    <span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token variable">$?</span> -eq <span class="token number">0</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>
      <span class="token builtin class-name">echo</span> <span class="token variable">$pretty_json</span>
    <span class="token keyword">else</span>
      <span class="token function">cat</span> /tmp/curls_body
      <span class="token builtin class-name">echo</span> <span class="token string">""</span>
    <span class="token keyword">fi</span>
    <span class="token builtin class-name">echo</span> <span class="token string">"<span class="token entity" title="\n">\n</span><span class="token variable">$response_code_and_method</span>"</span>
  <span class="token keyword">fi</span>
<span class="token punctuation">}</span></code></pre><p>In addition to providing a handful of &quot;default&quot; options to <code class="Code-sc-1amjnp4-0 fRlBcp">curl</code>, we get some other benefits including:</p><ul><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Pretty printing JSON responses with <code class="Code-sc-1amjnp4-0 fRlBcp">jq</code> (conditionally, when a response is parse-able as JSON)</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Using <code class="Code-sc-1amjnp4-0 fRlBcp">${CURL_OPTIONS[@]}</code>, we can provide additional options through an environment variable. This may be preferred for temporarily adding additional options, rather than hard-coding them in our reusable Bash function.<br/>Further details on this option are shown below: <a href="#additional-notes" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Additional Notes</a></p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>On the line <code class="Code-sc-1amjnp4-0 fRlBcp">$CURL_BASE_URL/$@</code>, a variable representing the API&#x27;s base URL is automatically inserted for us. This would be set to a value such as <code class="Code-sc-1amjnp4-0 fRlBcp">http://localhost:5000</code>. A trailing slash <code class="Code-sc-1amjnp4-0 fRlBcp">/</code> is appended, and our arguments provided to <code class="Code-sc-1amjnp4-0 fRlBcp">curls</code> are inserted here with <code class="Code-sc-1amjnp4-0 fRlBcp">$@</code>.</p></li></ul></div></div><a href="/blog/a-curl-helper-function-for-easy-api-testing" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/react-hooks-how-to-use-usememo" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">React Hooks: How to Use useMemo</h2><time dateTime="2021-03-05T21:29:51.159Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">March 5, 2021</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><blockquote class="TreeToJSX__BlockQuote-sc-1taxolb-1 bkGieB"><p>&quot;In computing, memoization or memoisation is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again.&quot;<br/><a href="https://en.wikipedia.org/wiki/Memoization" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Memoization - Wikipedia</a></p></blockquote><p><code class="Code-sc-1amjnp4-0 fRlBcp">useMemo</code> is a hook used to memoize values inside a React component. It&#x27;s a performance optimization to avoid recalculating expensive values on every render. You might be familiar with React&#x27;s <code class="Code-sc-1amjnp4-0 fRlBcp">memo</code> function, which is similar, but is used to memoize React components themselves, to avoid said re-renders in the first place.</p><p>The TypeScript function signature of <code class="Code-sc-1amjnp4-0 fRlBcp">useMemo</code>:</p><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-ts" tabindex="0"><code class="language-ts"><span class="token keyword">type</span> <span class="token class-name">useMemo</span> <span class="token operator">=</span> <span class="token operator">&lt;</span><span class="token constant">T</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token function-variable function">factory</span><span class="token operator">:</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token constant">T</span><span class="token punctuation">,</span> deps<span class="token operator">:</span> <span class="token builtin">Array</span><span class="token operator">&lt;</span><span class="token builtin">any</span><span class="token operator">></span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token constant">T</span><span class="token punctuation">;</span></code></pre><p>The first argument is a factory function returning the value we want to memoize. Like <code class="Code-sc-1amjnp4-0 fRlBcp">useEffect</code> and <code class="Code-sc-1amjnp4-0 fRlBcp">useCallback</code>, the second argument to this hook, <code class="Code-sc-1amjnp4-0 fRlBcp">deps</code>, is a dependency array. Changes to the values passed to this array will trigger our factory function to rerun, returning a new value. If the values in the dependency array do not change, we&#x27;ll instead receive the memoized value saved during the most recent execution of the factory function.</p></div></div><a href="/blog/react-hooks-how-to-use-usememo" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/react-hooks-how-to-use-useeffect" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">React Hooks: How to Use useEffect</h2><time dateTime="2021-03-04T18:04:42.446Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">March 4, 2021</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>Of all the hooks built into React, <code class="Code-sc-1amjnp4-0 fRlBcp">useEffect</code> is arguably the most difficult to understand. When I was learning React Hooks, I had just begun to get comfortable with class-based components and the lifecycle methods, such as <code class="Code-sc-1amjnp4-0 fRlBcp">componentDidMount</code>. Part of the difficulty I had when learning <code class="Code-sc-1amjnp4-0 fRlBcp">useEffect</code> was due to the fundamental differences between <code class="Code-sc-1amjnp4-0 fRlBcp">useEffect</code> and the legacy React lifecycle methods. The best tutorials I&#x27;ve read on <code class="Code-sc-1amjnp4-0 fRlBcp">useEffect</code> advise you to &quot;unlearn what you have learned&quot; in regard to lifecycle methods.</p><p><a href="https://overreacted.io/a-complete-guide-to-useeffect" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Dan Abramov has an excellent blog post on useEffect</a>. It&#x27;s very thorough, and thus a long read. This post will summarize many of the points Dan covers, and I&#x27;ll cover some of the issues and solutions I&#x27;ve discovered while using <code class="Code-sc-1amjnp4-0 fRlBcp">useEffect</code>.</p><p>First, here is the function signature for <code class="Code-sc-1amjnp4-0 fRlBcp">useEffect</code> as a TypeScript definition:</p><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-ts" tabindex="0"><code class="language-ts"><span class="token keyword">type</span> <span class="token class-name">useEffect</span> <span class="token operator">=</span> <span class="token punctuation">(</span>effect<span class="token operator">:</span> EffectCallback<span class="token punctuation">,</span> deps<span class="token operator">?</span><span class="token operator">:</span> <span class="token builtin">Array</span><span class="token operator">&lt;</span><span class="token builtin">any</span><span class="token operator">></span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token keyword">void</span><span class="token punctuation">;</span>
<span class="token keyword">type</span> <span class="token class-name">EffectCallback</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">|</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p><code class="Code-sc-1amjnp4-0 fRlBcp">EffectCallback</code> is our function to execute as the effect, which can optionally return a <a href="https://reactjs.org/docs/hooks-reference.html#cleaning-up-an-effect" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">cleanup function</a> that will be executed when the component unmounts, or when the effect is redefined. The optional second argument to <code class="Code-sc-1amjnp4-0 fRlBcp">useEffect</code>, <code class="Code-sc-1amjnp4-0 fRlBcp">deps</code>, is a &quot;dependency array&quot;. If <code class="Code-sc-1amjnp4-0 fRlBcp">deps</code> is omitted, then the effect will be executed (and redefined) after every render. When <code class="Code-sc-1amjnp4-0 fRlBcp">deps</code> is included, the effect is only redefined and executed if any of the values provided to the array change from one execution to the next. Consequently, providing no values to the dependency array, <code class="Code-sc-1amjnp4-0 fRlBcp">[]</code>, will result in the effect only being executed after the initial render. In determining if a dependency has changed, as far as I know, a strict equality comparison is performed (<code class="Code-sc-1amjnp4-0 fRlBcp">===</code>). Note that arrays, objects, and functions are only equal by reference. In some situations this can be problematic. This blog post provides several solutions:<br/><a href="https://www.benmvp.com/blog/object-array-dependencies-react-useEffect-hook" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Object &amp; array dependencies in the React useEffect Hook</a></p></div></div><a href="/blog/react-hooks-how-to-use-useeffect" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/create-a-typed-event-emitter-with-native-browser-apis" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Create a Typed Event Emitter with Native Browser APIs</h2><time dateTime="2021-02-24T19:56:02.926Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">February 24, 2021</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>You can create an event emitter in the browser, much like the Node.js <a href="https://nodejs.dev/learn/the-nodejs-event-emitter" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">EventEmitter</a> API. We&#x27;ll be using the <a href="https://developer.mozilla.org/en-US/docs/Web/API/EventTarget" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">EventTarget</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/CustomEvent" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">CustomEvent</a> browser APIs to achieve this. The browser support for these APIs is good, but if you need more browser coverage, there are also polyfills available, such as <a href="https://www.npmjs.com/package/custom-event-polyfill" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">custom-event-polyfill</a>. As a bonus, we can make the events and their details fully typed with TypeScript.</p><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-ts" tabindex="0"><code class="language-ts"><span class="token keyword">class</span> <span class="token class-name">EventEmitter</span> <span class="token keyword">extends</span> <span class="token class-name">EventTarget</span> <span class="token punctuation">{</span>
  <span class="token function">constructor</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>

  <span class="token generic-function"><span class="token function">on</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token constant">T</span> <span class="token keyword">extends</span> EventType<span class="token operator">></span></span></span><span class="token punctuation">(</span>
    type<span class="token operator">:</span> <span class="token constant">T</span><span class="token punctuation">,</span> <span class="token function-variable function">listener</span><span class="token operator">:</span> <span class="token punctuation">(</span>e<span class="token operator">:</span> CustomEvent<span class="token operator">&lt;</span>EventTypeToDetailMap<span class="token punctuation">[</span><span class="token constant">T</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token keyword">void</span>
  <span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">return</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">addEventListener</span><span class="token punctuation">(</span>type<span class="token punctuation">,</span> listener<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>

  <span class="token generic-function"><span class="token function">emit</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token constant">T</span> <span class="token keyword">extends</span> EventType<span class="token operator">></span></span></span><span class="token punctuation">(</span>
    type<span class="token operator">:</span> <span class="token constant">T</span><span class="token punctuation">,</span> detail<span class="token operator">:</span> EventTypeToDetailMap<span class="token punctuation">[</span><span class="token constant">T</span><span class="token punctuation">]</span>
  <span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">const</span> event <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">CustomEvent</span><span class="token punctuation">(</span>type<span class="token punctuation">,</span> <span class="token punctuation">{</span> detail <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">dispatchEvent</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">type</span> <span class="token class-name">EventType</span> <span class="token operator">=</span> <span class="token keyword">keyof</span> EventTypeToDetailMap<span class="token punctuation">;</span>

<span class="token keyword">type</span> <span class="token class-name">EventTypeToDetailMap</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token string-property property">'customEvent1'</span><span class="token operator">:</span> <span class="token builtin">number</span><span class="token punctuation">;</span>
  <span class="token string-property property">'customEvent2'</span><span class="token operator">:</span> <span class="token builtin">Array</span><span class="token operator">&lt;</span><span class="token builtin">string</span><span class="token operator">></span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span></code></pre><p>As we write event listeners and emitters for certain events, we get type checking for those specific events:</p><p><img src="/assets/typed-eventemitter-on.png" alt="type checking for EventEmitter.on" class="TreeToJSX__Img-sc-1taxolb-3 epTijp"/></p><p><img src="/assets/typed-eventemitter-emit.png" alt="type checking for EventEmitter.emit" class="TreeToJSX__Img-sc-1taxolb-3 epTijp"/></p></div></div><a href="/blog/create-a-typed-event-emitter-with-native-browser-apis" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/how-to-set-up-wsl-for-development" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">How to Set Up WSL for Development</h2><time dateTime="2021-02-23T23:13:25.100Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">February 23, 2021</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>WSL (Windows Subsystem for Linux) is a great way to gain access to a Linux OS through a command line interface. Being restricted to the CLI, WSL does require us to use Windows GUI programs. This, along with WSL being a subsystem that depends on Windows, does result in certain quirks that need to be worked around in order to utilize WSL to the fullest.</p><p>Some of these quirks to resolve include:</p><ul><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Synchronizing clipboards between WSL &amp; Windows</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Accessing files from both Windows and WSL</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Choosing the right terminal to access WSL through</p></li></ul><p>Due to the differences between WSL 1 &amp; 2, the solutions to some of these issues differ depending on the version in use. I&#x27;ll be focusing mainly on WSL 2 in this post, though I will cover some of the differences between WSL 1 &amp; 2.</p><h2 id="installation">Installation</h2></div></div><a href="/blog/how-to-set-up-wsl-for-development" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/hot-reloading-blog-preview-on-markdown-file-edit" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Hot Reloading Blog Preview on Markdown File Edit</h2><time dateTime="2021-02-20T16:23:26.604Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">February 20, 2021</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p><img src="/assets/blog-hot-reload.gif" alt="Side by side web browser and vim hot reloading" class="TreeToJSX__Img-sc-1taxolb-3 epTijp"/></p><p>When building this feature for my blog, what I wanted is the snappiness of an in-browser blog post editor, where you have a split view showing the editor on one side, and the rendered post on the other, instantaneously updated as you type into the editor. I used to use an in-browser editor for this purpose, but I now wanted the ability to edit inside my editor of choice, Vim.</p><p>You may have noticed in the gif above that the page only updates once I save the file. If you want something that updates as you type, you could opt for an auto-save solution like a plugin specific to your editor.</p><p>Since I&#x27;m using Next.js, which comes with its own preconfigured dev server, I needed to customize the Next.js dev server to add this functionality. This isn&#x27;t actually mandatory, as you could run an Express server separate from your Webpack / Next.js / other dev server, to be responsible for the file watching and WebSocket server.</p><p>For Next.js, there&#x27;s some good suggestions for how to achieve this in <a href="https://github.com/vercel/next.js/discussions/11419" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Next.js GitHub issue</a>. One of the suggestions I tried, the package <a href="https://github.com/hashicorp/next-remote-watch" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">next-remote-watch</a>, ended up being too sluggish for my liking. This is because the mechanism used is triggering an actual Next.js hot reload, the same as what happens when editing a source file.</p></div></div><a href="/blog/hot-reloading-blog-preview-on-markdown-file-edit" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/going-truly-serverless-with-nextjs-static-site-generation" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Going Truly Serverless with Next.js Static Site Generation</h2><time dateTime="2021-02-20T14:35:05.888Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">February 20, 2021</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>With the hype of the <a href="https://jamstack.org" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Jamstack</a>, and the benefits it offers, I made the switch from MERN stack to JAM stack for my blog. The most appealing benefits to me in my use case were:</p><ol><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Improved SEO, for my site that can be 100% statically generated.</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Simplified architecture. No more databases and servers, just files served from GitHub Pages.</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Using Git as my &quot;CMS&quot;. Switching from storing blog posts in a database, to storing them in <code class="Code-sc-1amjnp4-0 fRlBcp">.md</code> files, tracked by Git.</p></li></ol><h2 id="choosing-a-react-static-site-generator">Choosing a React Static Site Generator</h2><p>Coming from a MERN app, I needed a SSG solution for React. I considered choosing between three different options:</p><ul><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p><a href="https://github.com/gatsbyjs/gatsby" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Gatsby</a></p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p><a href="https://github.com/vercel/next.js" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Next.js</a></p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p><a href="https://github.com/react-static/react-static" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">React Static</a></p></li></ul></div></div><a href="/blog/going-truly-serverless-with-nextjs-static-site-generation" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/dockerizing-a-mern-app-for-development-and-production" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Dockerizing a MERN App for Development and Production</h2><time dateTime="2020-10-25T16:30:43.234Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">October 25, 2020</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>Creating a Dockerfile for a single service usually isn&#x27;t too bad. The example Dockerfile provided by the official guide for Node.js, <a href="https://nodejs.org/en/docs/guides/nodejs-docker-webapp/" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Dockerizing a Node.js web app</a>, can be copied almost exactly.</p><p>However, things start to get a little more complicated when we want to:</p><ul><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Create configurations for both development and production environments</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Enable hot reloading in development (avoid needing Docker to re-build for every change)</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Orchestrate connecting multiple services together (relevant for any web app with a frontend, backend, database, etc.)</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Persist data in a database between runs (with Docker volumes)</p></li></ul><p>The app I&#x27;ll be using as an example can be found here: <a href="https://github.com/zzzachzzz/zzzachzzz.github.io/tree/2ab6f0b10606162a57b946461c4dae74e2a295d5" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">https://github.com/zzzachzzz/zzzachzzz.github.io/tree/2ab6f0b10606162a57b946461c4dae74e2a295d5</a><br/>I will also include the various Docker files in this post.</p><blockquote class="TreeToJSX__BlockQuote-sc-1taxolb-1 bkGieB"><p><b>Edit (Feb. 15, 2021)</b><br/>Yep, that&#x27;s the source code for this site, at a prior commit. The site has since been migrated to Next.js with static site generation. To learn more about that, see the post:<br/><a href="/blog/going-truly-serverless-with-nextjs-static-site-generation" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Going Truly Serverless with Next.js Static Site Generation</a></p></blockquote></div></div><a href="/blog/dockerizing-a-mern-app-for-development-and-production" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/how-to-install-vim-with-clipboard-with-homebrew-on-linux" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">How to Install Vim with +clipboard with Homebrew on Linux</h2><time dateTime="2020-02-08T17:08:57.528Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">February 8, 2020</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><blockquote class="TreeToJSX__BlockQuote-sc-1taxolb-1 bkGieB"><p>Note: Or just install NeoVim and this should be a non-issue.</p></blockquote><p>Installing Vim with brew on OSX has worked flawlessly for me, and included +clipboard support. In my experience, working with Windows Subsystem for Linux specifically, a simple <code class="Code-sc-1amjnp4-0 fRlBcp">brew install vim</code> didn&#x27;t cut it, and <code class="Code-sc-1amjnp4-0 fRlBcp">vim --version</code> displayed that sad <code class="Code-sc-1amjnp4-0 fRlBcp">-clipboard</code>. I would prefer to use the same package manager between OSX and Linux, especially since I use a shell script for installing all my brew packages. In the past I&#x27;ve just resorted to installing vim-gtk to get a clipboard enabled build of vim on Linux. However, vim-gtk only yielded me version 8.0, while brew offered 8.2. I cared enough about this to open a GitHub issue and get a solution.</p><p><a href="https://github.com/Homebrew/linuxbrew-core/issues/19505" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Installing custom formula for Vim, options not present (+clipboard) - GitHub Issue</a></p><ol><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Install dependencies<br/><code class="Code-sc-1amjnp4-0 fRlBcp">sudo apt-get install libncurses5-dev libgnome2-dev libgnomeui-dev libgtk2.0-dev libatk1.0-dev libbonoboui2-dev libcairo2-dev libx11-dev libxpm-dev libxt-dev</code></p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Modify the vim formula<br/><code class="Code-sc-1amjnp4-0 fRlBcp">brew edit vim</code><br/>Change the configure option <code class="Code-sc-1amjnp4-0 fRlBcp">--without-x</code> to <code class="Code-sc-1amjnp4-0 fRlBcp">--with-x</code> and add the option <code class="Code-sc-1amjnp4-0 fRlBcp">--with-features=huge</code>. Save the changes.</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-bash" tabindex="0"><code class="language-bash">system <span class="token string">"./configure"</span>, <span class="token string">"--prefix=#{HOMEBREW_PREFIX}"</span>,
                      <span class="token string">"--mandir=#{man}"</span>,
                      <span class="token string">"--enable-multibyte"</span>,
                      <span class="token comment"># New options</span>
                      <span class="token string">"--with-x"</span>,
                      <span class="token string">"--with-features=huge"</span>,</code></pre></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Install the modified formula<br/><code class="Code-sc-1amjnp4-0 fRlBcp">brew install --build-from-source vim</code></p></li></ol><p>It is crucial to have the necessary dependencies installed. I tried these steps with the same formula options, <code class="Code-sc-1amjnp4-0 fRlBcp">--with-x</code> and <code class="Code-sc-1amjnp4-0 fRlBcp">--with-features=huge</code>, and my Vim installation <i>silently failed to include clipboard support, prior to installing the dependencies</i>. This is a major nuisance, and I hope to have raised some awareness of this issue, for a use case as common as installing Vim with clipboard support with Homebrew on Linux.</p></div></div><a href="/blog/how-to-install-vim-with-clipboard-with-homebrew-on-linux" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/piping-and-redirection-in-the-shell" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">|, &gt;, &gt;&gt;, &lt;, &lt;&lt;, &lt;&lt;&lt;, &lt;() Piping and Redirection in the Shell</h2><time dateTime="2020-01-06T22:53:59.386Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">January 6, 2020</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>Lately I&#x27;ve been learning Vim more in depth, beyond just Vim&#x27;s modal editing. With that, I&#x27;ve been learning more about Unix and the shell. As they say, &quot;Unix is an IDE&quot;, and Vim is just one of its tools. I&#x27;m going to keep it simple and use the terms input &amp; output to refer to stdin &amp; stdout, the more technically correct terms here.</p><p><code class="Code-sc-1amjnp4-0 fRlBcp">program &gt; file</code> Redirects the output of a program to a file. If the file exists, it will be overwritten (be careful).</p><p><code class="Code-sc-1amjnp4-0 fRlBcp">program &gt;&gt; file</code> Redirects the output of a program to a file. If the file exists, it will be appended to (safer option).</p><p><code class="Code-sc-1amjnp4-0 fRlBcp">program &lt; file</code> Redirects a file to be the input of a program. From what I can tell, this is rarely useful on its own, since nearly all programs which accept an input stream, also accept a file argument. Hence, these two are equivalent: <code class="Code-sc-1amjnp4-0 fRlBcp">cat &lt; file</code> &amp; <code class="Code-sc-1amjnp4-0 fRlBcp">cat file</code>. More details on that here:<br/><a href="https://askubuntu.com/a/883822" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">How does input redirection work? - Ask Ubuntu</a></p><p><code class="Code-sc-1amjnp4-0 fRlBcp">output | program</code> Redirects the output of a program, to be the input of another program.<br/>Example: <code class="Code-sc-1amjnp4-0 fRlBcp">echo $PATH | less</code><br/>This is functionally equivalent to:<br/><code class="Code-sc-1amjnp4-0 fRlBcp">echo $PATH &gt; temp_file &amp;&amp; less &lt; temp_file</code></p></div></div><a href="/blog/piping-and-redirection-in-the-shell" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/common-tasks-javascript-and-python-equivalents" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Common Tasks: JavaScript and Python Equivalents</h2><time dateTime="2019-11-13T05:06:20.818Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">November 12, 2019</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><h2 id="template-strings">Template Strings</h2><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-javascript" tabindex="0"><code class="language-javascript"><span class="token comment">// JavaScript</span>
<span class="token keyword">let</span> name <span class="token operator">=</span> <span class="token string">'Timmy'</span><span class="token punctuation">;</span>
console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>name<span class="token interpolation-punctuation punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">9</span><span class="token interpolation-punctuation punctuation">}</span></span><span class="token string"> btw haHAA</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Timmy: 12 btw haHAA</span></code></pre><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-python" tabindex="0"><code class="language-python"><span class="token comment"># Python (3.6+)</span>
name <span class="token operator">=</span> <span class="token string">'Timmy'</span><span class="token punctuation">;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>name<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">9</span><span class="token punctuation">}</span></span><span class="token string"> btw haHAA"</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment"># Timmy: 12 btw haHAA</span></code></pre><h2 id="ternary-operator">Ternary Operator</h2><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-javascript" tabindex="0"><code class="language-javascript"><span class="token comment">// JavaScript</span>
<span class="token keyword">let</span> x <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
x <span class="token operator">+=</span> <span class="token boolean">true</span> <span class="token operator">?</span> <span class="token number">1</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">;</span>
console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 1</span></code></pre></div></div><a href="/blog/common-tasks-javascript-and-python-equivalents" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/a-practical-guide-to-learning-vim" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">A Practical Guide to Learning Vim</h2><time dateTime="2019-09-17T18:49:28.000Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">September 17, 2019</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p><b>Edit (Jan. 11, 2020):</b> Since the creation of this blog post, I&#x27;ve begun using standalone Vim. My opinion hasn&#x27;t changed about the learning curve, and I don&#x27;t think there&#x27;s an overall advantage to using Vim over using an IDE/Editor with a Vim plugin. My incentive for learning Vim more in depth is because I enjoy the process of mastering the skill. The rest of this blog post will be left in its original state. Also, the <a href="https://github.com/JetBrains/ideavim" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">IdeaVim</a> plugin for JetBrains IDEs is the best I have used, even better than Neovintageous.</p><p>A more fitting title might be &quot;A Practical Guide to <i>Adopting</i> Vim&quot;. I&#x27;m not an advocate of Vim as an editor, I&#x27;m a fan of modal editing, of a mouse-free text editing experience. I think Vim as an editor can be great after extensively customizing it to your liking, but again, even the process of learning how to customize Vim adds even more to the learning curve. For this reason, I recommend you continue using your editor of choice... <i>with a Vim plugin to enable modal editing</i>.</p><p>Once someone has learned the basics of Vim&#x27;s keybindings, the next step is incorporating this new skill into their daily work, to develop the skill further, and train their muscle memory. One may attempt to switch to using Vim in their daily work, and quickly find their inability to be productive. Picking up Vim as an editor involves both learning Vim, and giving up all the features and keybindings you&#x27;re accustomed to in your last editor. Be it VSCode, Sublime, Atom, even picking up one of these editors and maximizing your productivity in it by learning its features and keyboard shortcuts is not a trivial task.</p><p>&quot;But Vim emulators suck, they&#x27;re not as good as real Vim. Just use Vim you filthy casual.&quot; I read too many comments of this nature in r/vim...<br/>While some plugins emulating Vim are worse than others, this statement of inferiority should not be a barrier to entry. People should learn Vim even only at a basic level. I&#x27;m not an expert, I don&#x27;t do fancy Vim trick shots in my daily editing. The most I&#x27;ve done is a macro, and the use case for this becomes very rare when I have multiple cursors in Sublime. I love too many of Sublime&#x27;s features to give it up! That&#x27;s why I feel I&#x27;ve struck an excellent balance of Vim features and Sublime features with my configuration. That&#x27;s the beauty of this, <i>you can keep the config you have and incrementally adopt Vim functionality, versus diving in head first.</i></p><p>I&#x27;m sure you can achieve a similar level of customization and features using a plugin for some other editor of your choice. My point of reference is the Neovintageous plugin for Sublime Text, so that&#x27;s what I&#x27;ll be covering in the remainder of this post.</p></div></div><a href="/blog/a-practical-guide-to-learning-vim" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/git-reference-keep-it-simple-common-workflows" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Git Reference: Keep it Simple. Common Workflows</h2><time dateTime="2019-09-03T19:28:34.000Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">September 3, 2019</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>Anywhere you see <code class="Code-sc-1amjnp4-0 fRlBcp">&lt;remote&gt;</code>, you should probably use <code class="Code-sc-1amjnp4-0 fRlBcp">origin</code>. More on origin vs upstream below.</p><h2 id="reference">Reference</h2><p><code class="Code-sc-1amjnp4-0 fRlBcp">git status</code> : display current branch and information on file changes</p><p><code class="Code-sc-1amjnp4-0 fRlBcp">git branch</code> : view all local branches</p><p><code class="Code-sc-1amjnp4-0 fRlBcp">git checkout &lt;branch&gt;</code> : switch to the specified branch</p></div></div><a href="/blog/git-reference-keep-it-simple-common-workflows" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/multiple-inheritance-in-python-method-resolution-order-mro" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Multiple Inheritance in Python: Method Resolution Order (MRO)</h2><time dateTime="2019-08-30T16:08:56.000Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">August 30, 2019</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-python" tabindex="0"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'A'</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'B'</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">C</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'D'</span><span class="token punctuation">)</span>

d <span class="token operator">=</span> D<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>When class <code class="Code-sc-1amjnp4-0 fRlBcp">D</code> is instantiated, what do you think will be the order of the print statements?</p><p>Python&#x27;s way of determining the order in which multiple inheritance is resolved is called the Method Resolution Order (MRO). The answer to the question is:</p><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-python" tabindex="0"><code class="language-python">A
C
B
D</code></pre><p>Lets see why.</p></div></div><a href="/blog/multiple-inheritance-in-python-method-resolution-order-mro" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/understanding-promises-in-javascript" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Understanding Promises in JavaScript</h2><time dateTime="2019-08-29T20:35:44.000Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">August 29, 2019</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>Promises are really confusing. There&#x27;s a lot of keywords associated with promises and async JS:</p><ul><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>Promise</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>resolve</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>reject</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>then</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>catch</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>async</p></li><li class="TreeToJSX__Li-sc-1taxolb-2 gacNJW"><p>await</p></li></ul><p>From MDN:</p><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-javascript" tabindex="0"><code class="language-javascript"><span class="token keyword">new</span> <span class="token class-name">Promise</span><span class="token punctuation">(</span>executor<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p><code class="Code-sc-1amjnp4-0 fRlBcp">executor</code></p></div></div><a href="/blog/understanding-promises-in-javascript" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article><article class="blog__Article-sc-gs9s1w-2 bbVJcj"><header class="blog__Header-sc-gs9s1w-3 blog___StyledHeader-sc-gs9s1w-4 jaiTdr kZIFNj"><a href="/blog/slatejs-draftjs-without-the-bad-parts" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink-sc-gs9s1w-7 gQnMzW iAkVvE"><h2 class="blog___StyledH2-sc-gs9s1w-10 hxRHcf">Slate.js: Draft.js without the Bad Parts</h2><time dateTime="2019-08-28T15:37:27.000Z" class="blog___StyledTime-sc-gs9s1w-11 eaEZEq">August 28, 2019</time></a></header><div class="blog__ContentPreview-sc-gs9s1w-0 iUHJLk"><div class="blog__Shadow-sc-gs9s1w-1 jqumEm"></div><div class="BlogContent__Container-sc-10yyr2o-0 gjkXwZ"><p>Anyone who has used Facebook&#x27;s open source package, <code class="Code-sc-1amjnp4-0 fRlBcp">Draft.js</code> knows that while it&#x27;s a powerful tool for building rich text editors, the API docs are underdeveloped, and can be very difficult to understand. The editor I wrote this blog post in was made by me with <code class="Code-sc-1amjnp4-0 fRlBcp">Slate.js</code>, and before I found that, I was struggling to learn how to make Draft.js do what I wanted it to do. I don&#x27;t have the expertise to go too into detail about comparing Slate and Draft, but a lot of that is covered here in the readme of Slate: <a href="https://github.com/ianstormtaylor/slate#principles" target="_blank" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv">Slate Principles</a>. Instead I&#x27;ll tell you about my use case: what I wanted to build with Draft, the problems I ran into, and how Slate made the process easier for me.</p><p>Given that this is a programming blog, the most important feature to me is beautiful code snippets with syntax highlighting. Like so:</p><pre class="TreeToJSX__Pre-sc-1taxolb-0 cTrNrc language-javascript" tabindex="0"><code class="language-javascript"><span class="token comment">// A JavaScript comment</span>
<span class="token keyword">const</span> language <span class="token operator">=</span> <span class="token string">'JavaScript'</span><span class="token punctuation">;</span>
console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">This is definitely </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>language<span class="token interpolation-punctuation punctuation">}</span></span><span class="token template-punctuation string">`</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// This is definitely JavaScript</span></code></pre><p>I had <code class="Code-sc-1amjnp4-0 fRlBcp">Prism.js</code> to handle the syntax highlighting.</p><p>I needed my editor to...</p></div></div><a href="/blog/slatejs-draftjs-without-the-bad-parts" target="_self" rel="noopener noreferrer" class="A__A_-sc-14fqd0c-0 oXjRv blog__BlogLink-sc-gs9s1w-5 blog___StyledBlogLink2-sc-gs9s1w-6 gQnMzW ckcSPp">Continue Reading</a></article></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"allPosts":[{"title":"Hitting a Target File Size With FFmpeg (Perfect for Discord Clips)","date":"2025-12-10T12:43:16.627Z","slug":"hitting-a-target-file-size-with-ffmpeg-perfect-for-discord-clips","content":"\nIf you've ever tried to send a gaming clip over Discord as a free user, you've run into the 10MB upload limit. My process before creating this script was to use a collection of other ffmpeg commands to trial-and-error trimming the clip, and lowering the quality until it finally went below the 10MB threshold.\n\nI wanted a way to say: **\"Here's my clip. Make it 10MB. Do what you must.\"**\n\nSo I wrote a Bash function that uses FFmpeg's 2‑pass encoding method to reliably target a specific file size. It also has quality‑of‑life options for trimming timestamps. As you'll see below, you can write other bash functions which call the main function to make this process happen by typing just a few characters into your terminal.\n\nMy setup:\n\n- Gaming on Windows, running the script in WSL (Git Bash will work too)\n- Shadowplay 1 minute instant replay saved videos\n- Discord 10MB file upload limit (non-Nitro paid users)\n\n## Requirements\n- A Bash shell to run the script: Linux, WSL, or Git Bash\n- FFmpeg (should include `ffmpeg` \u0026 `ffprobe`)\n\n**NOTE** I have FFmpeg installed in my Linux distro mounted in WSL (more on that [here](/blog/accessing-a-dual-boot-linux-install-in-wsl-with-chroot)), but using WSL with FFmpeg installed in Windows, with the exe accessible in your `$PATH` should work too.\n\n## The Scripts\n\nAlso available as a [GitHub Gist](https://gist.github.com/zzzachzzz/1a1e056160c5fd79262bf702022cfe59)\n\n### `vidunderfilesize.sh`\n\n```bash\n#!/usr/bin/env bash\n\neval set -- \"$(\n  getopt \\\n    --options s:e:i:o:k:a: \\\n    --longoptions start:,end:,input:,output:,output-filesize-kb:,audio-bitrate-kbps: \\\n    -- \"$@\"\n)\"\n\nwhile true; do\n  case \"$1\" in\n    -s|--start) start_arg=\"$2\"; shift 2 ;;\n    -e|--end) end_arg=\"$2\"; shift 2 ;;\n    -i|--input) input=\"$2\"; shift 2 ;;\n    -o|--output) output=\"$2\"; shift 2 ;;\n    -k|--output-filesize-kb) output_filesize_kb=\"$2\"; shift 2 ;;\n    -a|--audio-bitrate-kbps) audio_bitrate_kbps=\"$2\"; shift 2 ;;\n    --) shift; break ;;\n  esac\ndone\n\nIFS=\":\" read -ra start_array \u003c\u003c\u003c \"$start_arg\"\nIFS=\":\" read -ra end_array \u003c\u003c\u003c \"$end_arg\"\n\n# Prepend default zeros, filling arrays to 3 slots\nwhile (( ${#start_array[@]} \u003c 3 )); do\n  start_array=(0 ${start_array[@]})\ndone\nwhile (( ${#end_array[@]} \u003c 3 )); do\n  end_array=(0 ${end_array[@]})\ndone\n\n# Pad left 2 digits for each slot\nfor i in \"${!start_array[@]}\"; do\n  start_array[$i]=$(printf \"%02d\" ${start_array[$i]})\ndone\nfor i in \"${!end_array[@]}\"; do\n  end_array[$i]=$(printf \"%02d\" ${end_array[$i]})\ndone\n\nstart_hours_part=${start_array[0]}\nstart_minutes_part=${start_array[1]}\nstart_seconds_part=${start_array[2]}\nstart_seconds=$(( $start_seconds_part + $start_minutes_part * 60 + $start_hours_part * 60 * 60 ))\nstart_time=\"$start_hours_part:$start_minutes_part:$start_seconds_part\"\n\n# If no end timestamp supplied (or user provided zeroes), get duration of video\nif [[ \"${end_array[@]}\" == \"00 00 00\" ]]; then\n  raw_duration_decimal=\"$(\n    ffprobe -v error -select_streams v:0 -show_entries stream=duration \\\n    -of default=noprint_wrappers=1:nokey=1 \"$input\"\n  )\"\n  end_seconds=\"$(awk -v d=\"$raw_duration_decimal\" 'BEGIN {print int(d)}')\"\n  # `end_time` intentionally not set\nelse\n  end_hours_part=${end_array[0]}\n  end_minutes_part=${end_array[1]}\n  end_seconds_part=${end_array[2]}\n  end_seconds=$(( $end_seconds_part + $end_minutes_part * 60 + $end_hours_part * 60 * 60 ))\n  end_time=\"$end_hours_part:$end_minutes_part:$end_seconds_part\"\nfi\n\nduration_seconds=$(( $end_seconds - $start_seconds ))\n\ndefault_audio_bitrate_kbps=\"128\"\naudio_bitrate_kbps=\"${audio_bitrate_kbps:-$default_audio_bitrate_kbps}\"\naudio_total_kb=$(( $audio_bitrate_kbps * $duration_seconds ))\n\n_10MB_in_kb=\"80000\" # 10 megabyte == 80,000 kilobits\noutput_filesize_kb=${output_filesize_kb:-$_10MB_in_kb}\n\nvideo_bitrate_kbps=$(( ( $output_filesize_kb - $audio_total_kb ) / $duration_seconds ))\n\n# tmp file written to in 1st pass and read in 2nd pass\nffmpeg_stats_file=\"$(mktemp --tmpdir --dry-run ffmpeg_stats_XXXXXX)\"\n\nmaybe_to=\"$([[ -n $end_time ]] \u0026\u0026 echo \"-to $end_time\")\"\nffmpeg_common_output_file_options=\"\\\n-ss $start_time $maybe_to \\\n-c:v libx264 -b:v ${video_bitrate_kbps}k \\\n-maxrate 5M -bufsize 10M \\\n-passlogfile $ffmpeg_stats_file \\\n$FFMPEG_OUTPUT_FILE_OPTIONS\\\n\"\n\n# 1st pass ffmpeg analyzes video and outputs stats file to `$ffmpeg_stats_file*`,\n# to accurately target `$output_filesize_kb` based on specified bitrates.\nffmpeg -y -i \"$input\" \\\n  $ffmpeg_common_output_file_options \\\n  -pass 1 \\\n  -an -f mp4 \\\n  /dev/null\n\n# 2nd pass produces actual video output, reading from stats files produced in 1st pass\nffmpeg -i \"$input\" \\\n  $ffmpeg_common_output_file_options \\\n  -pass 2 \\\n  -c:a aac -b:a \"${audio_bitrate_kbps}k\" \\\n  \"$output\"\n\n# Clean up tmp files, mbtree file is ~20MB\nrm \"$ffmpeg_stats_file\"*.log{,.mbtree}\n\n```\n\nAdditionally, here is my own helper function I use for calling the main script. I suggest you create one too.\n\n```bash\nfunction meleeclip() {\n  local start=\"$1\"\n  local end=\"$2\"\n  local input=\"$3\"\n  local output=\"$4\"\n  # Defaults for empty start \u0026 end options handled in `vidunderfilesize.sh`\n  [[ \"$start\" == \"-\" ]] \u0026\u0026 start=\"\"\n  [[ \"$end\" == \"-\" ]] \u0026\u0026 end=\"\"\n\n  if [[ -z \"$input\" || \"$input\" == \"-\" ]]; then\n    local input_dir=\"/mnt/d/storage/Videos/shadowplay/slippi dolphin.exe\"\n    local newest_file=\"$(ls -tp \"$input_dir\" | grep -v \"/$\" | head -n 1)\"\n    input=\"${input_dir}/${newest_file}\"\n  fi\n\n  if [[ -z \"$output\" || \"$output\" == \"-\" ]]; then\n    local output_dir=\"/mnt/d/storage/Videos/shadowplay/slippi dolphin.exe/cropped-clips\"\n    local output_filename=\"_NEW_CLIP_NAME_ME_$(basename \"$input\")\"\n    output=\"${output_dir}/${output_filename}\"\n  fi\n\n  FFMPEG_OUTPUT_FILE_OPTIONS=\"-vf crop=in_h*4/3:in_h\" \\\n    ~/bin/vidunderfilesize.sh \\\n    --start=\"$start\" \\\n    --end=\"$end\" \\\n    --input=\"$input\" \\\n    --output=\"$output\"\n}\n```\n\n## Usage\n\n`FFMPEG_OUTPUT_FILE_OPTIONS` is an option you probably don't need. Here I am cropping to 4:3 aspect ratio to closely match [Slippi Dolphin Melee's](https://melee.tv) internal resolution of 73:60.\n\nThe `--start` and `--end` options allow you to specify the timestamps you want to trim the clip to. The parsing is flexible and allows for these example inputs, converting to `hh:mm:ss`.\n\n- `5` -\u003e `00:00:05`\n- `1:50` -\u003e `00:01:50`\n- `01:1:01` -\u003e `01:01:01`\n\nWith the `meleeclip` helper function I have, this is how I would typically call it:\n\n```bash\n# Let's say we want to clip from 00:00:36 to the end of my 1 minute clip\nmeleeclip 36\n\n# Or from 00:00:36 to 00:00:50\nmeleeclip 36 50\n```\n\nThat's it, since I have the `meleeclip` function default to use the newest file in my shadowplay directory as input, and a fixed output directory with a generated filename that I just go and rename separately after.\n\n## Explanation\n\nBitrate is predictable for producing a given filesize. File size is basically:\n\n```\nfile_size_bits ≈ bitrate_bits_per_sec × duration_sec\n```\n\nSo if you want a 10MB clip:\n\n```\n10 MB (Megabytes) = 80 Mb (megabits)\n10 MB = 80000 Kb (kilobits)\ntarget_bitrate_kbps = 80000 Kb / duration_seconds\n```\n\nIn the script, we calculate the maximum video bitrate we can use:\n```bash\nvideo_bitrate_kbps=$(( ( $output_filesize_kb - $audio_total_kb ) / $duration_seconds ))\n```\n\nOnce you know the exact bitrate needed, FFmpeg can aim for it, and using **2‑pass encoding**, it can hit that target very accurately.\n\n"},{"title":"Accessing a dual boot Linux install in WSL with chroot","date":"2024-10-11T14:49:56.465Z","slug":"accessing-a-dual-boot-linux-install-in-wsl-with-chroot","content":"\nGot a Windows \u0026 Linux dual boot setup? Rather than setting up a new WSL install, wouldn't it be nice to be able to \"import\" your existing native Linux install into WSL? While this method is not exactly an import, it is functionally similar.\n\n## Mounting the disk partition\n\nResources\n- [WSL 2 - Mounting a partitioned disk](https://learn.microsoft.com/en-us/windows/wsl/wsl2-mount-disk#mounting-a-partitioned-disk)\n- [EXT4 in Windows - Chris Titus Tech](https://www.youtube.com/watch?v=aX1vH1j7m7U)\n\nThe first step is mounting the partition containing your Linux install. If you only want to access the files of an ext4 partition from Windows, you'll only need this step.\n\nI have defined a couple of PowerShell functions to making mounting and unmounting easier:\n\n```powershell\n# These WSL (un)mount commands must be run in PowerShell as administrator\n\n# TODO: Replace the Model string with your own value: 'SHGS31-500GS-2'\n# TODO: Replace the parition number with your own value: 4\n\nFunction linuxmnt { wsl --mount (gcim -query \"SELECT * from Win32_DiskDrive WHERE Model = 'SHGS31-500GS-2'\" | select -expandproperty DeviceID) --partition 4 }\n\nFunction linuxunmnt { wsl --unmount (gcim -query \"SELECT * from Win32_DiskDrive WHERE Model = 'SHGS31-500GS-2'\" | select -expandproperty DeviceID) }\n```\n\nThe `linuxmnt` function will mount partition 4 of drive 0 in WSL at the mountpoint `/mnt/wsl/PHYSICALDRIVE0p4`. This path will vary based on the drive/device id and partition number you are targeting. The `linuxunmnt` will simply unmount all mountpoints for that drive.\n\nYou can include these in your PowerShell profile so they are always available. Your profile file path can be found with `echo $profile`, which will likely output one of the two following paths, depending on the version of PowerShell you are running:\n- `C:\\Users\\\u003cyour-user\u003e\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1`\n- `C:\\Users\\\u003cyour-user\u003e\\Documents\\PowerShell\\Microsoft.PowerShell_profile.ps1`\n\nYou'll need to modify the `linuxmnt` and `linuxunmnt` functions, as I have hardcoded the model (to choose the correct disk) and partition number I need to target.\n\n### Determining the device id\n\nBegin by querying for this information in PowerShell:\n\n```powershell\n\u003e gcim -query \"SELECT * from Win32_DiskDrive\"\nDeviceID           Caption                 Partitions Size          Model\n--------           -------                 ---------- ----          -----\n\\\\.\\PHYSICALDRIVE0 SHGS31-500GS-2          3          500105249280  SHGS31-500GS-2\n\\\\.\\PHYSICALDRIVE1 WDC WD1003FZEX-00K3CA0  1          1000202273280 WDC WD1003FZEX-00K3CA0\n\\\\.\\PHYSICALDRIVE2 ST2000DM008-2FR102      1          2000396321280 ST2000DM008-2FR102\n\\\\.\\PHYSICALDRIVE3 Samsung SSD 990 EVO 1TB 3          1000202273280 Samsung SSD 990 EVO 1TB\n```\n\nWe target the `Model` attribute rather than `DeviceID`, since the physical drive number can change if hardware is added or removed. Although, in the bash function below we hardcode the path `/mnt/wsl/PHYSICALDRIVE0p4`, physical drive 0. Something to be aware of, which could technically be made dynamic.\n\n### Determining the partition number\n\nTo determine the partition number containing the Linux filesystem, we can start with a bare mount, which will make all the drive's partitions visible in WSL, but without a mount point.\n\n```powershell\n# Run in PowerShell as administrator\nwsl --mount \\\\.\\PHYSICALDRIVEX --bare # Specify correct id instead of X\n```\n\nAfter the WSL bare mount, run `lsblk` from WSL.\n\n```\n$ lsblk\nNAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nsda      8:0    0 388.4M  1 disk\nsdb      8:16   0     2G  0 disk [SWAP]\nsdc      8:32   0 465.8G  0 disk\n├─sdc1   8:33   0   512M  0 part\n├─sdc3   8:35   0   3.7G  0 part\n└─sdc4   8:36   0 461.5G  0 part\nsdd      8:48   0     1T  0 disk /mnt/wslg/distro\n                                 /\n```\n\nBased on the partition sizes, I can see that `sdc4` is what I'm looking for, the main ext4 filesystem. If you want to inspect a partition further to verify, you can use `mount` in the usual way to mount its contents to a directory.\n\n## Chroot-ing into the Linux install\n\nThe helper function (named walter because that's the hostname that was chosen for the original native install):\n\n```bash\n# TODO: Replace PHYSICALDRIVE0p4 with the correct value based on the device id and partition number mounted\n# TODO: Replace zach with the user you wish to switch to\n\nfunction walter() {\n  if [[ ! -e /mnt/wsl/PHYSICALDRIVE0p4 ]]; then\n    echo \"'/mnt/wsl/PHYSICALDRIVE0p4' does not exist. Did you call linuxmnt?\"\n    return 1\n  fi\n  sudo mount -t proc /proc /mnt/wsl/PHYSICALDRIVE0p4/proc\n  sudo mount -t sysfs /sys /mnt/wsl/PHYSICALDRIVE0p4/sys 2\u003e /dev/null\n\n  sudo mount --rbind /dev /mnt/wsl/PHYSICALDRIVE0p4/dev\n  sudo mount --rbind /mnt /mnt/wsl/PHYSICALDRIVE0p4/mnt\n  sudo chroot /mnt/wsl/PHYSICALDRIVE0p4/ su zach\n}\n```\n\nAdd the above function to your `.bashrc` or other config file in your WSL install.\n\nRandom note, in my Debian WSL install, when I added a function to the `.bashrc` file, running `which walter` did not find the function, but `type walter` did. More on that [here](https://unix.stackexchange.com/a/10529).\n\nAt a minimum, all that's really needed is this line, `sudo chroot /mnt/wsl/PHYSICALDRIVE0p4/ su zach`, to choot into the mountpoint and switch from the root user to your regular user.\n\n`sudo mount --rbind /mnt /mnt/wsl/PHYSICALDRIVE0p4/mnt` - This is helpful so that the typical WSL mounts to access the Windows C:\\ drive (`/mnt/c`) and any additional drives are accessible.\n\nThe `/proc`, `/sys`, and `/dev` mounts are necessary for certain programs to work. In my case for `tmux`.\n\n## Bringing it all together: The Workflow\n\n1. Open PowerShell as Administrator and run `linuxmnt`\n2. Open a terminal for your WSL install, and run `walter` (or whatever you chose to name it).\n3. You have now chroot'd into your non-WSL Linux install! You'll have access to that shell and your installed programs, kind of as if you had SSH'd into it.\n\n"},{"title":"How to Change a Pacman Package's Dependencies on Arch Linux with remakepkg","date":"2022-10-22T20:13:29.318Z","slug":"how-to-change-a-pacman-packages-dependencies-on-arch-linux-with-remakepkg","content":"\nRecently I ran into a dependency conflict after an update of a particular package, [bitwarden-cli](https://archlinux.org/packages/community/any/bitwarden-cli/). Prior to version 2022.6.2-2, `bitwarden-cli` depended on `nodejs`. It was in version 2022.6.2-2 that the dependency was changed from `nodejs` to `nodejs-lts-gallium`.\n\nOkay, so what's the big deal? The big deal is that `nodejs` and `nodejs-lts-gallium` cannot both be installed, as they're listed as conflicting packages of one another (see the **Conflicts** section of [nodejs-lts-gallium](https://archlinux.org/packages/community/x86_64/nodejs-lts-gallium/)). While I could have just gone ahead and removed `nodejs` in favor of `nodejs-lts-gallium`, I didn't really want to, as I had no issues with it and wanted the latest version of `nodejs`. And yes, alternatively I could have installed the latest version via [nvm](https://github.com/nvm-sh/nvm) or otherwise, and kept `nodejs-lts-gallium` (version 16.x at the time of this writing) as the system dependency.\n\nFor whatever your personal reasons are, you may wish to remove or alter the restrictions defined for a package by a package maintainer. In my case, I was able to figure out why the dependency change occurred in the first place. It was due to [this bug](https://bugs.archlinux.org/task/74929), a bug which affected a premium feature of Bitwarden that I didn't even have access to. With this in mind, I felt comfortable discarding the new requirement of using `nodejs-lts-gallium`.\n\n**IMPORTANT NOTE**  \nIn writing this, I realized that `--assume-installed nodejs-lts-gallium` solves my problem, without the need for `remakepkg`. I just need to include that option during an upgrade, whenever there is a newer version of `bitwarden-cli` available. This works when dealing with the absence of a package. However, `remakepkg` may be needed for other scenarios. I'll proceed with how I used `remakepkg` to solve my problem.\n\nSo, how does one go about \"changing\" a package's dependency? It's done with the help of an AUR package, [remakepkg](https://aur.archlinux.org/packages/remakepkg). You can also find the git repo containing the script [here](https://gitlab.com/ayekat/pacman-hacks).\n\nFirst off, credit to this comment from the forum post, [nodejs-lts-gallium and nodejs are in conflict](https://bbs.archlinux.org/viewtopic.php?pid=2030394#p2030394). I owe the entirety of my solution to this comment. However for the non pacman experts, I'll provide some more details on how I solved my problem.\n\nPrior to discovering this solution, I had added the line `IgnorePkg = bitwarden-cli` to my `/etc/pacman.conf` file, preventing an upgrade of this package that introduced the `nodejs-lts-gallium` dependency. The problem is that upon removing this, and running `pacman -Syu`, I was prompted to remove the conflicting package `nodejs`, with the upgrade of `bitwarden-cli`. I needed to get the latest version of `bitwarden-cli`, but not actually install it until I had made the necessary dependency modifications. This is how I achieved that:\n\n```bash\npacman -S --downloadonly --assume-installed nodejs-lts-gallium bitwarden-cli\n```\n\nThere is another, less manual way to accomplish this. If you see the [author's guide to remakepkg](https://bbs.archlinux.org/viewtopic.php?id=234936), you'll see that the `remakepkg` command has the added convenience of downloading the latest version of a package from a mirror, independent of your system's main synced package database. More details on that [here](https://gitlab.com/ayekat/pacman-hacks/-/issues/43).\n\nMoving on with how I did this the manual way, after running the above pacman command to download `bitwarden-cli`, I was then able to access the downloaded package file from `/var/cache/pacman/pkg/bitwarden-cli-2022.10.0-1-any.pkg.tar.zst`. I copied this to another location to prepare a modified copy. Next, I created a file `rulefile`:\n```bash\nremove-depend nodejs-lts-gallium\nadd-depend nodejs\n```\nand supplied it to the `repkg` command:\n```bash\nrepkg -i ./bitwarden-cli-2022.10.0-1-any.pkg.tar.zst -r ./rulefile\n```\nThe `repkg` command produced an output modified package file:  \n`bitwarden-cli-2022.10.0-1.1-any.pkg.tar.xz`\n\nNotice the appended `.1` to the version info, and the alternate `xz` extension for the compression format.\n\nRunning `pacman -Qpi ./bitwarden-cli-2022.10.0-1.1-any.pkg.tar.xz`, we see that the dependency was replaced in the \"Depends On\" section:\n```\nName            : bitwarden-cli\nVersion         : 2022.10.0-1.1\nDescription     : The command line vault\nArchitecture    : any\nURL             : https://github.com/bitwarden/cli\nLicenses        : GPL3\nGroups          : None\nProvides        : bitwarden-cli=2022.10.0-1\nDepends On      : nodejs\n...\n```\n\nAll that's left now is to install the modified package:\n```bash\npacman -U ./bitwarden-cli-2022.10.0-1.1-any.pkg.tar.xz\n```\nYou can verify the installed version once again with `pacman -Qi bitwarden-cli`\n\nThat's it! As I mentioned above, `remakepkg` isn't necessary for my scenario, as pacman's `--assume-installed` option does the trick. However for more advanced dependency scenarios, `remakepkg` can come in handy.\n\n"},{"title":"A Curl Helper Function for Easy API Testing","date":"2021-09-06T18:23:42.735Z","slug":"a-curl-helper-function-for-easy-api-testing","content":"\nI tend to prefer command line tools for development, in this case choosing `curl` over Postman. Depending on the API that requests are being made to, curl commands can get out of hand, requiring numerous headers and other options to be manually attached on each request. The solution? Create a Bash helper function for curl, making our commands short and efficient.\n\nThe helper function:\n\n```bash\nfunction curls() {\n  local response_code_and_method\n  response_code_and_method=$(curl \\\n    --no-progress-meter \\\n    --write-out \"%{response_code} %{method}\" \\\n    --output /tmp/curls_body \\\n    --header \"Content-Type: application/json\" \\\n    ${CURL_OPTIONS[@]} \\\n    $CURL_BASE_URL/$@\n  )\n\n  if [ $? -eq 0 ]; then\n    local pretty_json\n    pretty_json=$(jq --color-output '.' /tmp/curls_body 2\u003e /dev/null)\n    if [ $? -eq 0 ]; then\n      echo $pretty_json\n    else\n      cat /tmp/curls_body\n      echo \"\"\n    fi\n    echo \"\\n$response_code_and_method\"\n  fi\n}\n```\n\nIn addition to providing a handful of \"default\" options to `curl`, we get some other benefits including:\n* Pretty printing JSON responses with `jq` (conditionally, when a response is parse-able as JSON)\n* Using `${CURL_OPTIONS[@]}`, we can provide additional options through an environment variable. This may be preferred for temporarily adding additional options, rather than hard-coding them in our reusable Bash function.  \nFurther details on this option are shown below: [Additional Notes](#additional-notes)\n* On the line `$CURL_BASE_URL/$@`, a variable representing the API's base URL is automatically inserted for us. This would be set to a value such as `http://localhost:5000`. A trailing slash `/` is appended, and our arguments provided to `curls` are inserted here with `$@`.\n\n## Example Usage\n\nCalling the endpoint `POST http://localhost:5000/test` with a request body can concisely be expressed as:\n\n`curls test -d '{\"key\": \"value\"}'`\n\nFull example with a minimal Flask app:\n\n![Full example with a minimal Flask app](/assets/curls-flask.png)\n\n## Additional Notes\n\n* Pretty printing JSON requires installing [jq](https://stedolan.github.io/jq/) (available from `brew`)\n* The `%{method}` formatter for the `--write-out` option requires curl 7.72.0+. \u003chttps://curl.se/changes.html#7_72_0\u003e  \nThe easiest way to install the latest version is `brew install curl` (OSX \u0026 Linuxbrew). For me on Ubuntu, the version available via `apt` was an older version.\n\n* To get a better understanding of the Bash function and to modify it to your liking, I recommend this Bash cheatsheet: \u003chttps://devhints.io/bash\u003e\n\n* Further explaining `${CURL_OPTIONS[@]}`, `CURL_OPTIONS` should be an array, whose elements are then expanded and space separated with `[@]`. For example, you may want to add another header containing your access token or API key.  \nExample: `CURL_OPTIONS=(\"--header\" \"Authorization: Bearer \u003cyour-access-token\u003e\")`\n\n"},{"title":"React Hooks: How to Use useMemo","date":"2021-03-05T21:29:51.159Z","slug":"react-hooks-how-to-use-usememo","content":"\n\u003e\"In computing, memoization or memoisation is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again.\"  \n[Memoization - Wikipedia](https://en.wikipedia.org/wiki/Memoization)\n\n`useMemo` is a hook used to memoize values inside a React component. It's a performance optimization to avoid recalculating expensive values on every render. You might be familiar with React's `memo` function, which is similar, but is used to memoize React components themselves, to avoid said re-renders in the first place.\n\nThe TypeScript function signature of `useMemo`:\n\n```ts\ntype useMemo = \u003cT\u003e(factory: () =\u003e T, deps: Array\u003cany\u003e) =\u003e T;\n```\n\nThe first argument is a factory function returning the value we want to memoize. Like `useEffect` and `useCallback`, the second argument to this hook, `deps`, is a dependency array. Changes to the values passed to this array will trigger our factory function to rerun, returning a new value. If the values in the dependency array do not change, we'll instead receive the memoized value saved during the most recent execution of the factory function.\n\n## Example\n```jsx\nfunction Todos({ todos, filterByStatus }) {\n  const filteredTodos = useMemo(() =\u003e {\n    return todos.filter(todo =\u003e todo.status === filterByStatus);\n  }, [todos, filterByStatus]);\n\n  return (\n    \u003cul\u003e\n      {filteredTodos.map((todo, i) =\u003e\n        \u003cli key={i}\u003e{todo.name}\u003c/li\u003e\n      )}\n    \u003c/ul\u003e\n  );\n}\n```\n\nWe receive the props `todos`, an array of todo objects, and `filterByStatus`, a string indicating the status we want to filter by, such as 'completed', 'in-progress', etc. If todo objects are added or removed from the `todos` array, that will affect the resulting `filteredTodos`. Likewise, the result will change if our `filterByStatus` changes from 'in-progress' to 'completed'. We include both of these variables in the dependency array to signal to `useMemo` that changes to these variables should trigger a recalculation of our computed `filteredTodos` value.\n\nNote that for `useMemo` to detect that the `todos` array is unchanged between renders, it must be equal by reference. The variables included in the dependency array will be compared to their previous values using strict equality (`===`). Remember that arrays, objects, and functions are only equal by reference:\n```js\n[1, 2, 3] === [1, 2, 3] // false\nlet x = [1, 2, 3];\nx === x // true;\n```\n\nUsing our example with the `todos` array prop, if that prop comes from a parent component storing the value as state:\n```js\nconst [todos, setTodos] = useState([]);\n```\n...then `todos` will remain referentially equal _until_ `setTodos` is called. You can test this out for yourself, by placing a `console.log` statement inside your `useMemo`'s factory function, to see when it is triggered.\n\n`useMemo` has a lot of concepts in common with `useEffect` and `useCallback`, and yet, at least to me, `useMemo` is a lot easier to understand. Perhaps that's because it seems less intuitive to memoize functions, in the case of `useEffect` and `useCallback`.\n\nFor a more detailed explanation of the dependency array, and other related concepts, you can check out:\n* My post on useEffect: [React Hooks: How to Use useEffect](/blog/react-hooks-how-to-use-useeffect)\n* [Object \u0026 array dependencies in the React useEffect Hook](https://www.benmvp.com/blog/object-array-dependencies-react-useEffect-hook)\n\n"},{"title":"React Hooks: How to Use useEffect","date":"2021-03-04T18:04:42.446Z","slug":"react-hooks-how-to-use-useeffect","content":"\nOf all the hooks built into React, `useEffect` is arguably the most difficult to understand. When I was learning React Hooks, I had just begun to get comfortable with class-based components and the lifecycle methods, such as `componentDidMount`. Part of the difficulty I had when learning `useEffect` was due to the fundamental differences between `useEffect` and the legacy React lifecycle methods. The best tutorials I've read on `useEffect` advise you to \"unlearn what you have learned\" in regard to lifecycle methods.\n\n[Dan Abramov has an excellent blog post on useEffect](https://overreacted.io/a-complete-guide-to-useeffect). It's very thorough, and thus a long read. This post will summarize many of the points Dan covers, and I'll cover some of the issues and solutions I've discovered while using `useEffect`.\n\nFirst, here is the function signature for `useEffect` as a TypeScript definition:\n\n```ts\ntype useEffect = (effect: EffectCallback, deps?: Array\u003cany\u003e) =\u003e void;\ntype EffectCallback = () =\u003e (void | (() =\u003e void));\n```\n\n`EffectCallback` is our function to execute as the effect, which can optionally return a [cleanup function](https://reactjs.org/docs/hooks-reference.html#cleaning-up-an-effect) that will be executed when the component unmounts, or when the effect is redefined. The optional second argument to `useEffect`, `deps`, is a \"dependency array\". If `deps` is omitted, then the effect will be executed (and redefined) after every render. When `deps` is included, the effect is only redefined and executed if any of the values provided to the array change from one execution to the next. Consequently, providing no values to the dependency array, `[]`, will result in the effect only being executed after the initial render. In determining if a dependency has changed, as far as I know, a strict equality comparison is performed (`===`). Note that arrays, objects, and functions are only equal by reference. In some situations this can be problematic. This blog post provides several solutions:  \n[Object \u0026 array dependencies in the React useEffect Hook](https://www.benmvp.com/blog/object-array-dependencies-react-useEffect-hook)\n\nWhy is it even necessary to have a dependency array? How could we be accessing stale values inside an effect?\n\nConsider the following snippet of vanilla JS:\n```js\nlet arr = [];\nlet y = 0;\n\nfunction pushFunc() {\n  y++;\n  let x = y;\n  arr.push(() =\u003e x);\n}\n\npushFunc();\npushFunc();\n\nconsole.log(arr[0]()); // 1\nconsole.log(arr[1]()); // 2\n```\nWe push two functions to an array, `() =\u003e x`, and each time this function is created, it captures `x` from its [closure](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures) within `pushFunc`. `x` from the first execution of `pushFunc` is not the same `x` in the second execution of `pushFunc`. When dealing with React, the same rules apply, whether those values come from props or state, as they're also just variables. This is because a React component is just a function, and plays by the same rules concerning function execution context.  \n1 render = 1 function call.\n\nIf we were to provide a function to `useEffect` with no dependency array; `useEffect(() =\u003e {...})`, the effect function we provide would be redefined after every render, receiving fresh values from the current execution context. The effect would also re-execute after every render. The dependency array serves two purposes:\n1. Tell React when to execute our effect\n2. Tell React when to redefine our effect\n\n## Example 1: Basic Usage with `fetch`\nThe most common use case for `useEffect` is fetching data from an API, and then updating the state of a component to render that data in the UI.\n\n```jsx\nfunction Todo({ id }) {\n  const [todo, setTodo] = useState();\n\n  useEffect(() =\u003e {\n    fetch(`/api/todos/${id}`)\n      .then(res =\u003e res.json())\n      .then(json =\u003e setTodo(json));\n  }, []);\n\n  if (!todo) return null;\n  return \u003cdiv\u003e{todo.title}\u003c/div\u003e;\n}\n```\n\nWhile we should avoid making too many comparisons to the class lifecycle methods, the above usage of `useEffect` with an empty dependency array `[]` is the rough equivalent of `componentDidMount`. The above does work in its current form, but we're lying to React about the dependency array. Running the above snippet through `eslint` configured with the rule `react-hooks/exhaustive-deps` gives us this warning:\n```\nReact Hook useEffect has a missing dependency: 'id'.\nEither include it or remove the dependency array\n```\nWe can fix this to become:\n\n```jsx\nuseEffect(() =\u003e {\n  ...\n}, [id]);\n```\n\nBy providing `id` to the dependency array we are saying:  \n\"Whenever `id` changes, redefine and rerun this effect.\"\n\n`id` may or may not change depending on how the parent component of our `Todo` component gets a todo id, and provides that prop. If our `Todo` component were to receive a different `id` prop, then we probably would want to fetch the todo corresponding to that new id, calling our effect provided to `useEffect` again.\n\nTechnically `setTodo` should be included in the dependency array too. However, since it is a function we get from our `useState` hook, its identity is guaranteed to be stable, so it will never change. Furthermore, **in newer versions of the `react-hooks/exhaustive-deps` rule, the linter won't tell us to include a `useState` `set_` function, nor the `dispatch` function returned by `useReducer`.** It's safe to omit these specific functions from the dependency array. Just not other functions, as we will see in the next section.\n\n## Example 2: Functions as Dependencies\nNext, let's take a look at functions as effect dependencies:\n\n```jsx\nfunction Todo({ id }) {\n  const [todo, setTodo] = useState();\n\n  function fetchTodo() {\n    return fetch(`/api/todos/${id}`);\n  }\n\n  useEffect(() =\u003e {\n    fetchTodo()\n      .then(res =\u003e res.json())\n      .then(json =\u003e setTodo(json));\n  }, []);\n\n  if (!todo) return null;\n  return \u003cdiv\u003e{todo.title}\u003c/div\u003e;\n}\n```\n\nIn this example, our effect calls a function, `fetchTodo`. This code contains a bug. :bug: Because we omit `fetchTodo` from our effect's dependency array, our effect captures only the original definition of `fetchTodo`, and in turn, that instance of `fetchTodo` only captures the initial value of the `id` prop. If `id` changes, our effect will reference the original stale value. Like in the first example, `id` is a dependency we need to inform our effect about. The difference is, we've now made that dependency indirect by accessing `id` inside `fetchTodo` rather than directly inside our effect callback.\n\nThere's a problem with simply adding `fetchTodo` to the dependency array to solve this. Because `fetchTodo` will be redefined on each render / execution of our `Todo` component, `fetchTodo` will have a new \"value\" / \"function identity\" each time, resulting in the effect being triggered on every render. There are two solutions to this problem:\n\n### Solution #1\nInclude `fetchTodo` in the dependency array, and define `fetchTodo` with [useCallback](https://reactjs.org/docs/hooks-reference.html#usecallback). Like `useEffect`, `useCallback` also accepts a dependency array. Because `fetchTodo` references `id` in its function body, we need to include `id` in its dependency array:\n\n```jsx\nconst fetchTodo = useCallback(() =\u003e {\n  return fetch(`/api/todos/${id}`);\n}, [id]); // Whenever `id` changes, `fetchTodo` will be redefined\n\nuseEffect(() =\u003e {\n  fetchTodo()\n    .then(res =\u003e res.json())\n    .then(json =\u003e setTodo(json));\n}, [fetchTodo]); // Add `fetchTodo` to the effect's dependency array\n```\n\n### Solution #2\nThe other solution is to extract `fetchTodo` from the component entirely. Being outside the closure of the `Todo` component, it won't have access to the `id` prop, but we can supply that as an argument to the function. Extracting `fetchTodo` will allow its function identity to be stable across renders of `Todo`:\n```jsx\nfunction Todo({ id }) {\n  const [todo, setTodo] = useState();\n\n  useEffect(() =\u003e {\n    fetchTodo(id) // Pass `id` as an argument\n      .then(res =\u003e res.json())\n      .then(json =\u003e setTodo(json));\n  }, [id]); // `fetchTodo` now has a stable function identity\n\n  if (!todo) return null;\n  return \u003cdiv\u003e{todo.title}\u003c/div\u003e;\n}\n\nfunction fetchTodo(id) { // Make `id` an argument\n  return fetch(`/api/todos/${id}`);\n}\n```\n\n## Example 3: Access Updated `props` Without Rerunning an Effect\nLet's look at another example. This one is a fairly unique case, as we need to access updated values in our effect, but re-executing the effect actually breaks the functionality we're going for:\n\n```jsx\nfunction Counter({ incrementBy }) {\n  const [num, setNum] = useState(0);\n\n  useEffect(() =\u003e {\n    const handle = setInterval(() =\u003e {\n      setNum(num + incrementBy);\n    }, 3000);\n\n    return () =\u003e clearInterval(handle);\n  }, [num, incrementBy]);\n\n  return \u003cdiv\u003e{num}\u003c/div\u003e;\n}\n```\n\n`setNum` won't change, but `num` and `incrementBy` are both problematic. With `num` in the dependency array, and our effect updating `num` via `setNum`, this will cause our effect to be triggered every time `setNum(num + incrementBy)` is run. For setting state relying on previous state values, we can use the callback form of `setState`, and remove `num` as a dependency.\n\nIf `num` is omitted from the dependency array, the linter will actually suggest this solution to us:\n\n```\nReact Hook useEffect has a missing dependency: 'num'.\nEither include it or remove the dependency array.\nYou can also do a functional update 'setNum(n =\u003e ...)'\nif you only need 'num' in the 'setNum' call\n```\n\nTo use the functional update form of `setState`, we can change this to:\n\n```jsx\nfunction Counter({ incrementBy }) {\n  const [num, setNum] = useState(0);\n\n  useEffect(() =\u003e {\n    const handle = setInterval(() =\u003e {\n      setNum(prevNum =\u003e prevNum + incrementBy); // `num` is no longer used here\n    }, 3000);\n\n    return () =\u003e clearInterval(handle);\n  }, [incrementBy]); // `num` removed from dependency array\n\n  return \u003cdiv\u003e{num}\u003c/div\u003e;\n}\n```\n\nNow we're left to deal with `incrementBy`. If this prop is updated, say from `10` to `20`, we do want that updated value to be referenced in our effect, rather than referencing a stale value. However, when our effect is redefined, we lose the timing of our interval, and a new interval is created. We have it setup to call `setNum(prevNum =\u003e prevNum + incrementBy)` every 3 seconds.\n\nWhat happens if just 1.5 seconds have passed for the interval, and the value of `incrementBy` changes?\n1. Our effect cleanup function we provided to React will be executed, `() =\u003e clearInterval(handle)`, clearing our current 3 second interval.\n2. Our effect will be redefined, creating a new 3 second interval, along with a new cleanup function.\n3. From there, 3 more seconds must pass before `setNum(...)` is called, for a total of 4.5 seconds since the last interval call (wrong behavior).\n\nThis example with `setInterval` provides us with a unique challenge. We want the updated values present in our effect, but we don't want the timing of our interval to be messed up, as a result of redefining our effect. `useReducer` can help us achieve this, by accessing updated props in our reducer function, rather than in `useEffect`:\n```jsx\nfunction Counter({ incrementBy }) {\n  const [num, incrementNum] = useReducer(\n    prevNum =\u003e prevNum + incrementBy, // Our \"setter\" (reducer function)\n    0 // Initial state\n  );\n\n  useEffect(() =\u003e {\n    const handle = setInterval(() =\u003e {\n      incrementNum();\n    }, 3000);\n\n    return () =\u003e clearInterval(handle);\n  }, []);\n\n  return \u003cdiv\u003e{num}\u003c/div\u003e;\n}\n```\nWe use `useReducer` in a similar fashion to `useState`, but with the ability to specify what our \"setter\" function does, and for it to access updated props. `useReducer` is flexible in how you use it for your state. It can be used for simple, single value state, or more complex state objects. By convention, you'd normally see `useReducer` used like this: `const [state, dispatch] = useReducer(...)`. We instead choose to name these `num` \u0026 `incrementNum`. `incrementNum` is our `dispatch` function that `useReducer` returns to us, and it is guaranteed to have a stable function identity, preventing it from triggering `useEffect` to rerun. Since `incrementNum` is the `dispatch` function returned to us by `useReducer`, it can be omitted from the dependency array and the exhaustive deps linter won't complain.\n\n\n## Conclusion\nHopefully this post helped in understanding `useEffect`. As you can tell, the design of this hook by the React team is something that's opinionated and strict in how it is intended to be used, though that's not a bad thing. Being honest about an effect's dependencies is important in avoiding subtle bugs. We looked at some tricks that can be used to limit the number of dependencies in our effects. These recommended workarounds to reduce dependencies are something I wish was documented a little better in the official React docs. One of the more helpful parts of the docs is the [Hooks FAQ #Performance Optimizations](https://reactjs.org/docs/hooks-faq.html#performance-optimizations) section, which to me seems like more of a general usage guide. Knowing these recommended strategies for working with `useEffect` is crucial, as I've found that it's very easy to \"break the rules\" of `useEffect` when building real world applications.\n"},{"title":"Create a Typed Event Emitter with Native Browser APIs","date":"2021-02-24T19:56:02.926Z","slug":"create-a-typed-event-emitter-with-native-browser-apis","content":"\nYou can create an event emitter in the browser, much like the Node.js [EventEmitter](https://nodejs.dev/learn/the-nodejs-event-emitter) API. We'll be using the [EventTarget](https://developer.mozilla.org/en-US/docs/Web/API/EventTarget) and [CustomEvent](https://developer.mozilla.org/en-US/docs/Web/API/CustomEvent) browser APIs to achieve this. The browser support for these APIs is good, but if you need more browser coverage, there are also polyfills available, such as [custom-event-polyfill](https://www.npmjs.com/package/custom-event-polyfill). As a bonus, we can make the events and their details fully typed with TypeScript.\n\n```ts\nclass EventEmitter extends EventTarget {\n  constructor() {\n    super();\n  }\n\n  on\u003cT extends EventType\u003e(\n    type: T, listener: (e: CustomEvent\u003cEventTypeToDetailMap[T]\u003e) =\u003e void\n  ) {\n    return this.addEventListener(type, listener);\n  }\n\n  emit\u003cT extends EventType\u003e(\n    type: T, detail: EventTypeToDetailMap[T]\n  ) {\n    const event = new CustomEvent(type, { detail })\n    return this.dispatchEvent(event);\n  }\n}\n\ntype EventType = keyof EventTypeToDetailMap;\n\ntype EventTypeToDetailMap = {\n  'customEvent1': number;\n  'customEvent2': Array\u003cstring\u003e;\n};\n```\n\nAs we write event listeners and emitters for certain events, we get type checking for those specific events:\n\n![type checking for EventEmitter.on](/assets/typed-eventemitter-on.png)\n\n![type checking for EventEmitter.emit](/assets/typed-eventemitter-emit.png)\n\n"},{"title":"How to Set Up WSL for Development","date":"2021-02-23T23:13:25.100Z","slug":"how-to-set-up-wsl-for-development","content":"\nWSL (Windows Subsystem for Linux) is a great way to gain access to a Linux OS through a command line interface. Being restricted to the CLI, WSL does require us to use Windows GUI programs. This, along with WSL being a subsystem that depends on Windows, does result in certain quirks that need to be worked around in order to utilize WSL to the fullest.\n\nSome of these quirks to resolve include:\n* Synchronizing clipboards between WSL \u0026 Windows\n* Accessing files from both Windows and WSL\n* Choosing the right terminal to access WSL through\n\nDue to the differences between WSL 1 \u0026 2, the solutions to some of these issues differ depending on the version in use. I'll be focusing mainly on WSL 2 in this post, though I will cover some of the differences between WSL 1 \u0026 2.\n\n## Installation\nIf you haven't already, follow the [installation guide from Microsoft](https://docs.microsoft.com/en-us/windows/wsl/install-win10) to get WSL installed, preferably WSL 2. One possible reason you would need to settle for WSL 1, is if your version of Windows is not new enough, as covered in the guide. Another problem which I once ran into when installing WSL 2, is virtualization not being enabled in my PC's BIOS. I was halted with the error:\n\u003e \"Please enable the Virtual Machine Platform Windows feature and ensure virtualization is enabled in the BIOS.\"\n\nThe setting you need to enable in your BIOS may be called \"Intel Virtualization Technology\" or similar depending on your CPU and motherboard.\n\n## Synchronizing Clipboards\nWhile you may be able to copy text from your WSL terminal to your Windows clipboard by highlighting it with the mouse, programs in WSL such as Tmux or Vim copy text to the Linux clipboard, rather than to the Windows clipboard. In order to synchronize the two, the solution I've used is an X server, VcXsrv. To set this up you can follow these [instructions from a GitHub comment](https://github.com/Microsoft/WSL/issues/892#issuecomment-275873108), with one exception if you're on WSL 2. Due to the way networking was changed between WSL 1 \u0026 2, instead of adding `export DISPLAY=localhost:0.0` to your `.bashrc` / `.zshrc` in step 5, add these two lines:\n```bash\nexport DISPLAY=$(awk '/nameserver / {print $2; exit}' /etc/resolv.conf 2\u003e/dev/null):0\nexport LIBGL_ALWAYS_INDIRECT=1\n```\nAlso, those instructions don't mention how to have VcXsrv start up automatically. For that, you'll want to move the `config.xlaunch` file it creates to the Windows startup directory: `C:\\Users\\\u003cYOUR-USER\u003e\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\`\n\n## Accessing Files from Both Windows and WSL\nThis is something that has changed a lot between WSL 1 \u0026 2. In WSL 1, opening files from the Linux filesystem with a Windows program [was a no go](https://devblogs.microsoft.com/commandline/do-not-change-linux-files-using-windows-apps-and-tools), and it was instead recommended to keep those shared files in the Windows filesystem, that both Windows and Linux could access. When I was using WSL 1, I would keep all my git repos in a Windows directory, and symlink it for quick access to my Ubuntu home directory, at `~/_`. I used this underscore directory as a sort of \"shared home directory\" for Windows \u0026 Linux.\n\nHowever in WSL 2, it is now recommended to keep those files in the Linux filesystem, for performance reasons. Now Windows is able to access the Linux filesystem as a network drive. You can view your Linux filesystem from the Windows File Explorer, by typing `\\\\wsl$` into its address bar. There's only one limitation I'm aware of with this network drive approach: symlinks.\n\nTaking my use case as an example, I keep my configuration files in a \"dotfiles\" git repo. When developing on WSL and using VSCode on Windows, I would need to keep my dotfiles repo in the Windows filesystem in order to create a Windows symlink (`mklink /D \"\u003ctarget-dir\u003e\" \"\u003csource-dir\u003e\"` in `cmd.exe`) that links those config files to the directory that VSCode looks for them. That's one case to consider before you put everything in the Linux filesystem.\n\n## Choosing a Terminal for WSL\nThe default terminal you get upon opening the Ubuntu Windows app (or other distro) is okay, but may be lacking some features or config options you've come to expect. Unless you're using Tmux, you're probably missing multiple terminal tabs. You can get this feature from the [Windows Terminal](https://www.microsoft.com/en-us/p/windows-terminal/9n0dx20hk701), from the Microsoft Store. My personal choice is [wsl-terminal](https://github.com/mskyaxl/wsl-terminal).\n"},{"title":"Hot Reloading Blog Preview on Markdown File Edit","date":"2021-02-20T16:23:26.604Z","slug":"hot-reloading-blog-preview-on-markdown-file-edit","content":"![Side by side web browser and vim hot reloading](/assets/blog-hot-reload.gif)\n\nWhen building this feature for my blog, what I wanted is the snappiness of an in-browser blog post editor, where you have a split view showing the editor on one side, and the rendered post on the other, instantaneously updated as you type into the editor. I used to use an in-browser editor for this purpose, but I now wanted the ability to edit inside my editor of choice, Vim.\n\nYou may have noticed in the gif above that the page only updates once I save the file. If you want something that updates as you type, you could opt for an auto-save solution like a plugin specific to your editor.\n\nSince I'm using Next.js, which comes with its own preconfigured dev server, I needed to customize the Next.js dev server to add this functionality. This isn't actually mandatory, as you could run an Express server separate from your Webpack / Next.js / other dev server, to be responsible for the file watching and WebSocket server.\n\nFor Next.js, there's some good suggestions for how to achieve this in [Next.js GitHub issue](https://github.com/vercel/next.js/discussions/11419). One of the suggestions I tried, the package [next-remote-watch](https://github.com/hashicorp/next-remote-watch), ended up being too sluggish for my liking. This is because the mechanism used is triggering an actual Next.js hot reload, the same as what happens when editing a source file.\n\nI ended up creating my own solution, utilizing:\n* File watching (via [chokidar](https://www.npmjs.com/package/chokidar))\n* WebSockets ([ws](https://www.npmjs.com/package/ws) for the dev server, and the built in browser [WebSocket API](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API) for the client)\n* [Next.js custom server](https://nextjs.org/docs/advanced-features/custom-server) (only for development, not production)\n\nThese are the source files relevant for this feature:\n\n* [dev-server.ts](https://github.com/zzzachzzz/zzzachzzz.github.io/blob/master/dev-server.ts) - Custom Next.js server, responsible for file watching and the WebSocket server.\n* [/blog/edit/[slug].tsx](https://github.com/zzzachzzz/zzzachzzz.github.io/blob/master/pages/blog/edit/%5Bslug%5D.tsx) - Wrapper component for the blog post page, which connects to the WebSocket server.\n* [/blog/[slug].tsx](https://github.com/zzzachzzz/zzzachzzz.github.io/blob/master/pages/blog/%5Bslug%5D.tsx) - The blog post page, that receives either static props from Next, or when in edit mode, dynamic props from the above wrapper component that manages the WebSocket connection.\n"},{"title":"Going Truly Serverless with Next.js Static Site Generation","date":"2021-02-20T14:35:05.888Z","slug":"going-truly-serverless-with-nextjs-static-site-generation","content":"\nWith the hype of the [Jamstack](https://jamstack.org), and the benefits it offers, I made the switch from MERN stack to JAM stack for my blog. The most appealing benefits to me in my use case were:\n1. Improved SEO, for my site that can be 100% statically generated.\n2. Simplified architecture. No more databases and servers, just files served from GitHub Pages.\n3. Using Git as my \"CMS\". Switching from storing blog posts in a database, to storing them in `.md` files, tracked by Git.\n\n## Choosing a React Static Site Generator\n\nComing from a MERN app, I needed a SSG solution for React. I considered choosing between three different options:\n* [Gatsby](https://github.com/gatsbyjs/gatsby)\n* [Next.js](https://github.com/vercel/next.js)\n* [React Static](https://github.com/react-static/react-static)\n\nThe two most popular React frameworks are Gatsby \u0026 Next.js. Gatsby is a very powerful tool that emphasizes a plugin ecosystem. Gatsby can do a lot. As I went through Gatsby's vast documentation, I was having difficulty figuring out how to do what I wanted to do, for my fairly simple use case. After this experience, I was drawn to the simplicity of React Static. Ultimately, I ended up choosing Next.js for a few different reasons, one being their documentation coupled with their collection of examples on GitHub. I used their [blog-starter template](https://github.com/vercel/next.js/tree/canary/examples/blog-starter) as a starting point. Another reason I chose Next is their great out-of-the-box TypeScript support.\n\nThe last minor thing that sealed the deal for my decision, was the React team announcing that they are collaborating with the Next.js team on React's new experimental feature, \"Server Components\". Relevant links:\n* [Introducing Zero-Bundle-Size React Server Components](https://reactjs.org/blog/2020/12/21/data-fetching-with-react-server-components.html)\n* [(Timestamp in the talk where Dan Abramov mentions the Next.js collab)](https://youtu.be/TQQPAU21ZUw?t=2570)\n\nWhile not a huge factor, it gave me the impression that the design philosophies of Next.js and the React core team align the most closely, and that Next.js would be receiving first-class support for this feature.\n\n## Migrating from MERN to JAM\nSource code can be found here:\n* Post-migration GitHub source: \u003chttps://github.com/zzzachzzz/zzzachzzz.github.io/tree/master\u003e\n* Pre-migration GitHub source: \u003chttps://github.com/zzzachzzz/zzzachzzz.github.io/tree/2ab6f0b10606162a57b946461c4dae74e2a295d5\u003e\n\nAside from the usual steps to migrate a common React app to a Next.js React app, there were a few other things I needed to handle in the migration. There would be changes to accommodate for the removal of a server; no Express \u0026 no MongoDB. There would also be some small changes to account for a React app utilizing SSG or SSR (server-side rendering), specifically the way CSS is loaded, depending on the tool you use for CSS.\n\n### MongoDB to .md Files\nFor moving the content from MongoDB to markdown files, I created a migration script: [backend/migrations/db-to-markdown-file.js](https://github.com/zzzachzzz/zzzachzzz.github.io/blob/fc62221055adea46ef43803c973b28445262c448/backend/migrations/db-to-markdown-file.js)\n\n### CSS for SSG / SSR\nDepending on which tool you use for CSS, Next.js documents how to use it in SSG \u0026 SSR here: \u003chttps://nextjs.org/docs/basic-features/built-in-css-support\u003e\n\nFrom there, they link to examples on their GitHub. I use `styled-components`, so I followed their example here: \u003chttps://github.com/vercel/next.js/tree/canary/examples/with-styled-components\u003e\n\n### Hosting a Static Site on GitHub Pages\nIn addition to the `next build` script, to deploy a fully static site without a server, the `next export` script is used: \u003chttps://nextjs.org/docs/advanced-features/static-html-export\u003e\n\nWhen hosting the static build on a git branch on GitHub Pages, the naming of the exported `_next/` directory triggers Jekyll on GitHub Pages, as directories with a leading underscore have a special meaning to Jekyll. This unexpected side effect resulted in 404s for certain static assets my site was trying to fetch. To disable Jekyll processing on GitHub pages, we need to provide a `.nojekyll` file at the root. This was my final build script in my `package.json` file:  \n`\"build\": \"next build \u0026\u0026 next export \u0026\u0026 touch ./out/.nojekyll\"`  \nMore info here: \u003chttps://github.blog/2009-12-29-bypassing-jekyll-on-github-pages\u003e\n\nWhile not mandatory, I do recommend the [gh-pages](https://www.npmjs.com/package/gh-pages) npm package if you do intend to deploy to GitHub Pages. By default it will push to a branch named `gh-pages`. You'll want to configure your GitHub repo's settings to serve GitHub Pages from this branch. In conjunction with the build script I mentioned above, this was my deploy script:  \n`\"deploy\": \"yarn run build \u0026\u0026 gh-pages --dist out --dotfiles\"`  \n`out/` is the default output directory name for a Next.js static export, and we need to include the option `--dotfiles` for the `.nojekyll` file to be included in the push to the `gh-pages` branch.\n\n### Getting Prism.js to Work with SSG / SSR\nI never found it straightforward to set up Prism.js for code highlighting in a React app. When my pages were still being rendered client-side, I used `React.useEffect` to trigger Prism to highlight all code blocks:\n```jsx\nReact.useEffect(() =\u003e {\n  Prism.highlightAll();\n}, []);\n```\nWhile I could still have the effect be performed client-side, I wanted to go all in on having my site be fully statically generated. In my [TreeToJSX.tsx](https://github.com/zzzachzzz/zzzachzzz.github.io/blob/master/components/TreeToJSX.tsx) component, responsible for rendering a markdown document tree to JSX, I came up with the following solution to have the Prism highlighted HTML be built:\n```tsx\n// Add leading whitespace to \u003ccode\u003e className due to className mismatch caused by Prism injecting class\nconst CodeBlock = ({ lang, children }: { lang?: string; children: string; }) =\u003e {\n  const langCls = ` language-${lang || 'none'}`;\n  if (lang) {\n    const highlightedCode = Prism.highlight(children, Prism.languages[lang], lang);\n    return (\n      \u003cPre className={langCls}\u003e\n        \u003ccode className={\" \" + langCls} dangerouslySetInnerHTML={{__html: highlightedCode}}\u003e\u003c/code\u003e\n      \u003c/Pre\u003e\n    );\n  } else {\n    return (\n      \u003cPre className={langCls}\u003e\n        \u003ccode className={\" \" + langCls}\u003e{children}\u003c/code\u003e\n      \u003c/Pre\u003e\n    );\n  }\n};\n```\nPrism offers a low level `highlight` function that will return stringified HTML of the syntax highlighted code we provide in the string `children`. I was getting a warning about a mismatching className between the client and server (server in development, for SSG). The mismatch was caused by leading whitespace in one but not the other: `\" language-jsx\"` vs `\"language-jsx\"`. This was some oddity caused by the way Prism injects CSS classes, that I was able to workaround by adding leading whitespace to the class names.\n\n## Hot Reloading a Rendered Blog Post Upon its Markdown File Being Edited\n\nI outline this feature in a separate post:  \n[Hot Reloading Blog Preview on Markdown File Edit](/blog/hot-reloading-blog-preview-on-markdown-file-edit)\n\n![Side by side web browser and vim hot reloading](/assets/blog-hot-reload.gif)\n\n"},{"title":"Dockerizing a MERN App for Development and Production","date":"2020-10-25T16:30:43.234Z","slug":"dockerizing-a-mern-app-for-development-and-production","content":"\nCreating a Dockerfile for a single service usually isn't too bad. The example Dockerfile provided by the official guide for Node.js, [Dockerizing a Node.js web app](https://nodejs.org/en/docs/guides/nodejs-docker-webapp/), can be copied almost exactly.\n\nHowever, things start to get a little more complicated when we want to:\n* Create configurations for both development and production environments\n* Enable hot reloading in development (avoid needing Docker to re-build for every change)\n* Orchestrate connecting multiple services together (relevant for any web app with a frontend, backend, database, etc.)\n* Persist data in a database between runs (with Docker volumes)\n\nThe app I'll be using as an example can be found here: \u003chttps://github.com/zzzachzzz/zzzachzzz.github.io/tree/2ab6f0b10606162a57b946461c4dae74e2a295d5\u003e  \nI will also include the various Docker files in this post.\n\n\u003e**Edit (Feb. 15, 2021)**  \n\u003eYep, that's the source code for this site, at a prior commit. The site has since been migrated to Next.js with static site generation. To learn more about that, see the post:  \n[Going Truly Serverless with Next.js Static Site Generation](/blog/going-truly-serverless-with-nextjs-static-site-generation)\n\nTo Dockerize a React app, we'll definitely want a config for development, and production. In development, webpack-dev-server (`npm run [start|react-scripts-start]` in CRA) will be used with hot-reloading. In production, there are multiple ways to go about it, but I'll be using Nginx to serve the bundle, and proxying `/api` requests to the Express app.\n\n`frontend/Dockerfile.dev`:\n```dockerfile\nFROM node:14\nWORKDIR /usr/src/frontend\nCOPY package*.json ./\nRUN npm install\nEXPOSE 3000\nCMD [\"npm\", \"run\", \"start\"]\n```\n\nOne thing to note for proxying requests in development. If using CRA, you've likely set `\"proxy\": \"http://localhost:\u003cport\u003e\"` in `package.json` before, to proxy requests from React to a server, like Express. When running the frontend and the backend in separate Docker containers, they don't share the same localhost. Instead, we need to provide the network address created by Docker to connect the two together. You'll see more of this in later steps involving the Docker Compose `.yml` files, but as far as Webpack is concerned, we'll need to provide it a config file for the proxy: \n\n`frontend/src/setupProxy.js`:\n```js\nconst { createProxyMiddleware } = require('http-proxy-middleware');\n\nconst EXPRESS_HOST = process.env.EXPRESS_HOST || 'localhost';\n\nmodule.exports = function(app) {\n  app.use(\n    '/api',\n    createProxyMiddleware({\n      target: `http://${EXPRESS_HOST}:5000`\n    })\n  );\n};\n```\n\nSince I don't know of a way to embed an environment variable in the `package.json` file, this more advanced `setupProxy.js` file is necessary. Notice the environment variable `EXPRESS_HOST`. We will provide this variable to our Docker container, through our Docker Compose config. More on the above proxy config here: \u003chttps://create-react-app.dev/docs/proxying-api-requests-in-development/#configuring-the-proxy-manually\u003e\n\n`frontend/Dockerfile.prod`:\n```dockerfile\nFROM node:14 as builder\nWORKDIR /usr/src/frontend\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\n\nFROM nginx\nCOPY --from=builder /usr/src/frontend/build /usr/share/nginx/html\nCOPY nginx.conf /etc/nginx/conf.d/\nEXPOSE 8080\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n```\n\nThis is considered a multi-stage Docker build, due to the multiple `FROM` statements. We build our Webpack bundle, beginning from the `node:14` base image, and then switch to the `nginx` base image to serve that Webpack bundle. Notice the line `COPY nginx.conf /etc/nginx/conf.d/`, which refers to a `nginx.conf` file I keep in Git.\n\n`frontend/nginx.conf`:\n```\nserver {\n    listen 8080;\n\n    location /api {\n        proxy_pass http://backend:5000;\n    }\n\n    location / {\n        root /usr/share/nginx/html;\n        try_files $uri /index.html;\n    }\n}\n```\n\n**Note that my `nginx.conf` is a bit abnormal**, since my server hosting the site has another Nginx instance running outside of Docker, which I have setup with `location / { proxy_pass http://localhost:8080; }`. I have it setup this way so I can host multiple sites, and have Nginx handle routing traffic based on the `server_name`. You'll probably want your `nginx.conf` setup to include sections for Certbot, to manage SSL certificates, and listen on port 80 \u0026 443. Consult another tutorial on Certbot \u0026 Nginx for that.\n\nThe portion of this `nginx.conf` file that is applicable to you is the `proxy_pass` setup for `/api` requests, which sends it to the network host `backend` on port `5000`. This is Docker managing networking again. In this case, `backend`, is the name of our docker-compose service for Express, so Docker provides us the address for that specific container under the hostname `backend`.\n\nBefore we get to those Docker Compose files that link everything together, there's one more Dockerfile:\n\n`backend/Dockerfile`:\n```dockerfile\nFROM node:14\nWORKDIR /usr/src/backend\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nEXPOSE 5000\nCMD [\"node\", \"app.js\"]\n```\n\nFor the backend, I don't currently have a separate dev \u0026 prod Dockerfile, however I would recommend it, with the use of `nodemon` in place of `node` in the `CMD` statement in `Dockerfile.dev`, to enable hot reloading in development.\n\nNow onto the `docker-compose.yml` files. I have 3 of these under the filenames `docker-compose.yml`, `docker-compose.override.yml`, and `docker-compose.prod.yml`. You can choose different filenames, but there is a rational for these specific filenames. Both `docker-compose.yml` and `docker-compose.override.yml` are [filenames that Docker specifically looks for](https://docs.docker.com/compose/extends/). In both dev \u0026 prod, we use 2 of these 3 docker-compose files.\n\n* `docker-compose.yml` - The base config for dev \u0026 prod\n* `docker-compose.override.yml` - The dev config overrides\n* `docker-compose.prod.yml` - The prod config overrides\n\nAs shown in the Docker Compose docs linked above, multiple compose files can be specified with `-f` like so (also see `docker-compose --help`):  \n`docker-compose -f docker-compose.yml -f docker-compose.prod.yml [COMMAND] [ARGS...]`\n\nCompose files specified are read from left to right, which means `docker-compose.prod.yml` will be read last, giving it priority over our base `docker-compose.yml`.\n\nIf no files are specified with `-f`, Docker will do this:\n`docker-compose -f docker-compose.yml -f docker-compose.override.yml [COMMAND] [ARGS...]`\n\nWhy does this matter? In development, when you want to use the dev config, **you don't have to specify compose files for every `docker-compose` command you want to execute**. Running your entire application's stack in development becomes one short command: `docker-compose up`. That's it. Finally, here are those compose files:\n\n`docker-compose.yml`:\n```yml\nversion: \"3.8\"\n\nservices:\n  frontend:\n    build:\n      context: ./frontend\n    environment:\n      EXPRESS_HOST: backend\n\n  backend:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    ports:\n      - \"5000:5000\"\n    env_file: ./backend/.env\n    environment:\n      HOST: 0.0.0.0\n      MONGO_HOST: mongo\n\n  mongo:\n    image: mongo:latest\n    ports:\n      - \"127.0.0.1:27017:27017\"\n    volumes:\n      - mongo-data:/data/db\n\nvolumes:\n  mongo-data:\n```\n\n`docker-compose.override.yml`:\n```yml\nservices:\n  frontend:\n    build:\n      dockerfile: ./Dockerfile.dev\n    ports:\n      - \"3000:3000\"\n    environment:\n      NODE_ENV: development\n    volumes:\n      - ./frontend:/usr/src/frontend\n      - /usr/src/frontend/node_modules\n    # Due to stupid react-scripts bug still present in v3.4.3\n    # https://github.com/facebook/create-react-app/issues/8688\n    stdin_open: true\n\n  backend:\n    environment:\n      NODE_ENV: development\n    volumes:\n      - ./backend:/usr/src/backend\n      - /usr/src/backend/node_modules\n```\n\n`docker-compose.prod.yml`:\n```yml\nservices:\n  frontend:\n    build:\n      dockerfile: ./Dockerfile.prod\n    ports:\n      - \"127.0.0.1:8080:8080\"\n    environment:\n      NODE_ENV: production\n\n  backend:\n    environment:\n      NODE_ENV: production\n```\n\nThere's a lot we could go over in these compose files. I mentioned in the beginning that we want to enable hot-reloading in development, so that changes to code made on our host computer, are reflected in our Docker container, triggering a hot-reload from webpack-dev-server (or nodemon). The way we reflect file changes between host and container is through specifying `volumes`:\n\n```yml\nvolumes:\n  - ./frontend:/usr/src/frontend\n  - /usr/src/frontend/node_modules\n```\n\n`./frontend:/usr/src/frontend` maps our host's `./frontend` directory, to our container's `/usr/src/frontend` directory. Since our host may have its own `node_modules` directory inside `./frontend`, we don't want this to be shared with the container. The container needs to maintain its own installed dependencies in isolation. To prevent our container's `node_modules` from being overwritten, we create an anonymous volume of our container's `/usr/src/frontend/node_modules` directory. The ordering of the two volumes listed is important, so that our container's `node_modules` stored in a volume have highest priority (applied last). I would recommend doing other research on Docker volumes to better understand the different types of volumes that Docker supports. Just note that we can tell Docker to persist its own `node_modules` by creating an anonymous volume (we don't assign a name to it), that Docker keeps track of with a generated hash as the volume name. This volume persists between container instances.\n\nOn the subject of volumes, another volume is very important to persist data in our Mongo database. Without a volume, our Mongo data would be lost every time out container stops and starts again, and we definitely don't want to lose our DB data, at least in production. You'll notice this volume is mentioned in two places:\n\n```yml\n  mongo:\n    image: mongo:latest\n    ports:\n      - \"127.0.0.1:27017:27017\"\n    volumes:\n      - mongo-data:/data/db\n\nvolumes:\n  mongo-data:\n```\n\nWhy does `mongo-data` appear twice? In this situation, we're using a \"named volume\" (again, highly recommend reading more on these volume types). A named volume behaves quite similar to the anonymous volume I described earlier, except it's named! We could technically make this volume anonymous, but it's good to be able to identify the volume in case we need to manipulate it somehow, like making a backup of our database data. Named volumes must be defined in the top-level `volumes` key, that's why it appears in two places, unlike anonymous volumes.\n\nSee the Docker Compose docs on volumes: \u003chttps://docs.docker.com/compose/compose-file/#volumes\u003e\n\nYou may have noticed that ports are usually mapped like `\"\u003cport\u003e:\u003cport\u003e\"`, without specifying a host. With this shorthand, the host is implied to be `0.0.0.0`, listening on all interfaces. This makes it publicly accessible outside of the machine. If you don't need to directly access Mongo (via the Mongo shell) remotely, and can instead do so over SSH, I highly recommend that for security. Especially with the default Mongo config for Docker, there will be no credentials required to access Mongo. This means that an attacker who only knows the IP address of your server can remotely access your database! Yes, I did learn that the hard way, thankfully with non-consequential data. :sweat_smile: So do yourself a favor and specify the mapping `127.0.0.1:27017:27017` (`localhost` for the host, implicit `0.0.0.0` for the container).\n"},{"title":"How to Install Vim with +clipboard with Homebrew on Linux","date":"2020-02-08T17:08:57.528Z","slug":"how-to-install-vim-with-clipboard-with-homebrew-on-linux","content":"\n\u003eNote: Or just install NeoVim and this should be a non-issue.\n\nInstalling Vim with brew on OSX has worked flawlessly for me, and included +clipboard support. In my experience, working with Windows Subsystem for Linux specifically, a simple `brew install vim` didn't cut it, and `vim --version` displayed that sad `-clipboard`. I would prefer to use the same package manager between OSX and Linux, especially since I use a shell script for installing all my brew packages. In the past I've just resorted to installing vim-gtk to get a clipboard enabled build of vim on Linux. However, vim-gtk only yielded me version 8.0, while brew offered 8.2. I cared enough about this to open a GitHub issue and get a solution.\n\n[Installing custom formula for Vim, options not present (+clipboard) - GitHub Issue](https://github.com/Homebrew/linuxbrew-core/issues/19505)\n\n1.  Install dependencies  \n    `sudo apt-get install libncurses5-dev libgnome2-dev libgnomeui-dev libgtk2.0-dev libatk1.0-dev libbonoboui2-dev libcairo2-dev libx11-dev libxpm-dev libxt-dev`\n2.  Modify the vim formula  \n    `brew edit vim`  \n    Change the configure option `--without-x` to `--with-x` and add the option `--with-features=huge`. Save the changes.\n3.  ```bash\n    system \"./configure\", \"--prefix=#{HOMEBREW_PREFIX}\",\n                          \"--mandir=#{man}\",\n                          \"--enable-multibyte\",\n                          # New options\n                          \"--with-x\",\n                          \"--with-features=huge\",\n    ```\n4.  Install the modified formula  \n    `brew install --build-from-source vim`\n\nIt is crucial to have the necessary dependencies installed. I tried these steps with the same formula options, `--with-x` and `--with-features=huge`, and my Vim installation _silently failed to include clipboard support, prior to installing the dependencies_. This is a major nuisance, and I hope to have raised some awareness of this issue, for a use case as common as installing Vim with clipboard support with Homebrew on Linux.\n"},{"title":"|, \u003e, \u003e\u003e, \u003c, \u003c\u003c, \u003c\u003c\u003c, \u003c() Piping and Redirection in the Shell","date":"2020-01-06T22:53:59.386Z","slug":"piping-and-redirection-in-the-shell","content":"\nLately I've been learning Vim more in depth, beyond just Vim's modal editing. With that, I've been learning more about Unix and the shell. As they say, \"Unix is an IDE\", and Vim is just one of its tools. I'm going to keep it simple and use the terms input \u0026 output to refer to stdin \u0026 stdout, the more technically correct terms here.\n\n`program \u003e file` Redirects the output of a program to a file. If the file exists, it will be overwritten (be careful).\n\n`program \u003e\u003e file` Redirects the output of a program to a file. If the file exists, it will be appended to (safer option).\n\n`program \u003c file` Redirects a file to be the input of a program. From what I can tell, this is rarely useful on its own, since nearly all programs which accept an input stream, also accept a file argument. Hence, these two are equivalent: `cat \u003c file` \u0026 `cat file`. More details on that here:  \n[How does input redirection work? - Ask Ubuntu](https://askubuntu.com/a/883822)\n\n`output | program` Redirects the output of a program, to be the input of another program.  \nExample: `echo $PATH | less`  \nThis is functionally equivalent to:  \n`echo $PATH \u003e temp_file \u0026\u0026 less \u003c temp_file`\n\n## Herestrings \u0026 Heredocs\n\n[Here Strings - The Linux Documentation Project](https://tldp.org/LDP/abs/html/x17837.html)\n\n`program \u003c\u003c\u003c string` Redirects a string to be the input of a program (stdin).  \nExample:  \n`python \u003c\u003c\u003c \"print(len('Dude no way'))\"\n11`\n\n`program \u003c\u003c delimiter\nmulti-line string\ndelimiter` Redirects a multi-line string to be the input of a program (stdin).  \nExample:  \n```bash\npython \u003c\u003c EOF\nheredoc\u003e print('Sooo')\nheredoc\u003e print('Powerful')\nheredoc\u003e EOF\nSooo\nPowerful\n```\nEOF (end of file) is just a convention here, the delimiter could be almost any sequence of characters.\n\n## Process Substitution\n\n`program \u003c(output)` Redirects the output of a program to a temp file, to be treated as a file argument.  \nExamples:  \n```bash\n$ ls -l \u003c(echo hi)\nlr-x------ 1 zach zach 64 Oct  3 07:35 /proc/self/fd/11 -\u003e 'pipe:[23068]'\n\n$ cat \u003c(echo hi)\nhi\n\n$ echo foo | python3 \u003c(echo \"import sys; print('python stdin:', sys.stdin.read())\")\npython stdin: foo\n\n# Useful for vim diffing outputs, since vimdiff only accepts file arguments\n$ vimdiff \u003c(/usr/local/bin/vim --version) \u003c(/usr/bin/vim --version)\n...\n```\n"},{"title":"Common Tasks: JavaScript and Python Equivalents","date":"2019-11-13T05:06:20.818Z","slug":"common-tasks-javascript-and-python-equivalents","content":"\n## Template Strings\n\n```javascript\n// JavaScript\nlet name = 'Timmy';\nconsole.log(`${name}: ${3+9} btw haHAA`);  // Timmy: 12 btw haHAA\n```\n\n```python\n# Python (3.6+)\nname = 'Timmy';\nprint(f\"{name}: {3+9} btw haHAA\");  # Timmy: 12 btw haHAA\n```\n\n## Ternary Operator\n\n```javascript\n// JavaScript\nlet x = 0;\nx += true ? 1 : 0;\nconsole.log(x);  // 1\n```\n\n```python\n# Python\nx = 0\nx += 1 if True else 0\nprint(x)  # 1\n```\n\n## Array / List Manipulation\n\n```javascript\n// JavaScript\nlet x = [3];  // x: [3]\nx.push(5);  // x: [3, 5]\nlet y = x;  // x: [3, 5], y: [3, 5]\nconsole.log(x == y);  // true\n// Clone an array (shallow copy)\ny = [...x];  // x: [3, 5], y: [3, 5]\n// Or\ny = x.slice()\nconsole.log(x == y);  // false\n// Check for equality\nconsole.log(x.length === y.length \u0026\u0026 x.every((e, i) =\u003e e === y[i]))  // true\nx.pop()  // x: [3], y: [3, 5]\nconsole.log(x.length === y.length \u0026\u0026 x.every((e, i) =\u003e e === y[i]))  // false\n```\n\n```python\n# Python\nx = [3]  # x: [3]\nx.append(5)  # x: [3, 5]\ny = x  # x: [3, 5], y: [3, 5]\nprint(x is y)  # True\n# Clone a list (shallow copy)\ny = x.copy()  # x: [3, 5], y: [3, 5]\n# Or\ny = list(x)\nprint(x is y)  # False\n# Check for equality\nprint(x == y)  # True\nx.pop()  # x: [3], y: [3, 5]\nprint(x == y)  # False\n```\n\n## Reading \u0026 Writing JSON Files\n\n```javascript\n// JavaScript\nconst fs = require('fs');\n\nfs.writeFileSync('data.json', JSON.stringify({a: 1, b: 2}, null, 4));\nlet data = JSON.parse(fs.readFileSync('data.json'));\nconsole.log(data);  // {a: 1, b: 2}\n```\n\n```python\n# Python\nimport json\n\nwith open('data.json', 'w') as file:\n    json.dump({'a': 1, 'b': 2}, file, indent=4)\nwith open('data.json', 'r') as file:\n    data = json.load(file)\nprint(data)  # {'a': 1, 'b': 2}\n```\n\n## For Loops and Iteration\n\n```javascript\n// JavaScript\nconst arr = ['a', 'b'];\n\nfor (let i = 0; i \u003c arr.length; i++) {\n  console.log(i, arr[i]);  // 0 'a' , 1 'b'\n}\n\nfor (const x of arr) {\n  console.log(x);  // a , b\n}\n\nconst obj = {a: 1, b: 2};\n\nfor (const key in obj) {\n  console.log(key, obj[key]);  // a 1 , b 2\n}\n\nfor (const [key, value] of Object.entries(obj)) {\n  console.log(key, value);  // a 1 , b 2\n}\n```\n\n```python\n# Python\narr = ['a', 'b']\n\nfor i in range(len(arr)):\n    print(i, arr[i])  # 0 a , 1 b\n\nfor x in arr:\n    print(x)  # a , b\n\nobj = {'a': 1, 'b': 2}\n\nfor key in obj:\n    print(key, obj[key])  # a 1 , b 2\n\nfor key, value in obj.items():\n    print(key, value)  # a 1 , b 2\n```\n\n## List Comprehension / Array Map\n\n```javascript\n// JavaScript\nlet arr = Array.from({length: 4}, _ =\u003e null);\nconsole.log(arr);  // [null, null, null, null]\n\narr = [1, 2, 3, 4].map(x =\u003e x % 2 === 0 ? true : false);\nconsole.log(arr);  // [false, true, false, true]\n\narr = [1, 2, 3, 4].filter(x =\u003e x % 2 === 0).map(x =\u003e x + 100);\nconsole.log(arr);  // [102, 104]\n// OR in a single iteration:\narr = [1, 2, 3, 4].reduce((filtered, x) =\u003e {\n  if (x % 2 === 0) filtered.push(x + 100);\n  return filtered;\n}, []);\nconsole.log(arr);  // [102, 104]\n```\n\n```python\n# Python\narr = [None for i in range(4)]\nprint(arr)  # [None, None, None, None]\n\narr = [True if x % 2 == 0 else False for x in [1, 2, 3, 4]]\nprint(arr)  # [False, True, False, True]\n\narr = [x + 100 for x in [1, 2, 3, 4] if x % 2 == 0]\nprint(arr)  # [102, 104]\n```\n\nMore to come\n\n\\_\\_\\_\n"},{"title":"A Practical Guide to Learning Vim","date":"2019-09-17T18:49:28.000Z","slug":"a-practical-guide-to-learning-vim","content":"\n**Edit (Jan. 11, 2020):** Since the creation of this blog post, I've begun using standalone Vim. My opinion hasn't changed about the learning curve, and I don't think there's an overall advantage to using Vim over using an IDE/Editor with a Vim plugin. My incentive for learning Vim more in depth is because I enjoy the process of mastering the skill. The rest of this blog post will be left in its original state. Also, the [IdeaVim](https://github.com/JetBrains/ideavim) plugin for JetBrains IDEs is the best I have used, even better than Neovintageous.\n\nA more fitting title might be \"A Practical Guide to _Adopting_ Vim\". I'm not an advocate of Vim as an editor, I'm a fan of modal editing, of a mouse-free text editing experience. I think Vim as an editor can be great after extensively customizing it to your liking, but again, even the process of learning how to customize Vim adds even more to the learning curve. For this reason, I recommend you continue using your editor of choice... _with a Vim plugin to enable modal editing_.\n\nOnce someone has learned the basics of Vim's keybindings, the next step is incorporating this new skill into their daily work, to develop the skill further, and train their muscle memory. One may attempt to switch to using Vim in their daily work, and quickly find their inability to be productive. Picking up Vim as an editor involves both learning Vim, and giving up all the features and keybindings you're accustomed to in your last editor. Be it VSCode, Sublime, Atom, even picking up one of these editors and maximizing your productivity in it by learning its features and keyboard shortcuts is not a trivial task.\n\n\"But Vim emulators suck, they're not as good as real Vim. Just use Vim you filthy casual.\" I read too many comments of this nature in r/vim...  \nWhile some plugins emulating Vim are worse than others, this statement of inferiority should not be a barrier to entry. People should learn Vim even only at a basic level. I'm not an expert, I don't do fancy Vim trick shots in my daily editing. The most I've done is a macro, and the use case for this becomes very rare when I have multiple cursors in Sublime. I love too many of Sublime's features to give it up! That's why I feel I've struck an excellent balance of Vim features and Sublime features with my configuration. That's the beauty of this, _you can keep the config you have and incrementally adopt Vim functionality, versus diving in head first._\n\nI'm sure you can achieve a similar level of customization and features using a plugin for some other editor of your choice. My point of reference is the Neovintageous plugin for Sublime Text, so that's what I'll be covering in the remainder of this post.\n\nVintage, Six, Vintageous, Neovintageous, which Vim plugin do I choose? I started with the Vintage package, which comes bundled with Sublime, but the package is set to be ignored by default. Sublime's stock offering of Vim emulation with Vintage met my needs just fine for a while, and I didn't see any reason to switch. The small tweaks I needed, such as binding jj to \u0026lt;Esc\u003e, was covered by a tweak to Sublime's JSON formatted settings.\n\nI eventually discovered the power of a well configured vimrc, and went in search for how I could include one in my Sublime Vim setup. Through some random comment I stumbled across on some forum, someone mentioned the capability of the Neovintageous package to allow you to include a .neovintageous file, the equivalent of a .vimrc file. I cannot believe that this feature is not advertised more on [Neovintageous's GitHub](https://github.com/NeoVintageous/NeoVintageous) readme. While they state that it is highly configurable, there is no mention of a .neovintageousrc file in the readme. I am shocked by this.\n\nThis is a killer feature, and for me it would have been the one thing to tempt me to abandon Sublime and force myself to learn all of Vim, beyond just its modal editing. For the record, I'm not allergic to Vim. I use it every day for quick file edits, but it doesn't have the allure that Sublime does on me. When you discover the power of a .vimrc, you may become addicted to making it your own, and improving upon some of Vim's less desirable default key mappings.\n\nI don't have a ton of modifications, but I'll share what I do have, as well as my motive behind each remap. If you want more, you can look on GitHub at some of the Vim customization repos with thousands of stars, and hundreds of lines of modifications. I prefer to keep it a little bit simpler. By the way, the file goes in your Sublime User folder with your other customizations. Example path on a Windows machine: `C:\\Users\\\u003cyour user\u003e\\AppData\\Roaming\\Sublime Text 3\\Packages\\User\\.neovintageousrc`\n\nJust before I get into the `.neovintageousrc`, I know of one keybinding that needs to be assigned in the regular Sublime keybinding settings, and it's the most important one:\n\n```javascript\n{\n    \"keys\": [\"j\", \"j\"],\n    \"command\": \"_enter_normal_mode\",\n    \"args\": {\"mode\": \"mode_insert\"},\n    \"context\": [{\"key\": \"vi_insert_mode_aware\"}]\n},\n```\n\n`jj` for exiting insert mode, instead of having to reach over to press `\u003cEsc\u003e`. This is a popular one. `jk` is another good alternative. Onto the rest of the key mappings...  \n\n\n## `.neovintageousrc`\n\n`noremap J 5j` Shift + j moves the cursor down 5 lines  \n`noremap K 5k` Shift + k moves the cursor up 5 lines  \n`noremap W 5w` Shift + w moves the cursor forward 5 words  \n`noremap B 5b` Shift + b moves the cursor backwards 5 words\n\nThese 4 navigation mappings just make sense to me, `J` and `K` in particular. I don't think I'd seen these elsewhere. I don't like counting lines and words every time I wanna move around in Vim, so instead I would end up spamming `j` and `k`. I think this strikes a good balance for medium distance movement, without the need to first hit an arbitrary number key, and then my intended movement command. This way, I can just hold shift and fly around.  \n  \n  \n`noremap M J` Join lines with M\n\nAh but wait! I just replaced another very important default keybinding for joining lines with J. Yes, so I opted for a key next to it, M, which by default moves your cursor to the middle of the screen. This could also be a useful one, but I didn't find myself using it. Customize as you wish.  \n  \n  \n`noremap 0 ^`  \n`noremap ^ 0`\n\nHere I'm swapping the keys responsible for moving the cursor to the beginning of the line, and moving the cursor to the first non-whitespace character (skip the indentation). The latter I find far more useful, so I made it the key that's easier to press, `0`.  \n  \n  \n`noremap $ g_`\n\n`$` moves the cursor to the end of the line and includes the newline character. So if you yank and paste that, you'll get an extra line. `g_` is one of those random vim bindings under the g 'namespace', and it moves the cursor to the end of the line, excluding the newline character. Much better.  \n  \n  \n``noremap m `\nnoremap ` m``\n\nHere, I'm swapping the key for creating a mark and going to a mark. I go to marks far more often than I create them, so it makes sense to me to make goto mark easier to press with `m`.  \n  \n  \n`noremap \u003clt\u003e ,` Translates to `noremap \u003c ,` but `\u003c` is a special character in the vimrc syntax  \n`noremap , ;`\n\nNormally when using `f` or `t` to find a character in a line, you would use `;` to jump to the next result, and `,` to jump to the previous result. What I've done here, is sort of mimic the logic of `n` and `N` for going to the next and previous result in a Vim search. You're using the same key, but holding `Shift` to do the reverse. This pattern is seen all throughout default Vim keybindings. With `,` and `\u003c`, the mapping becomes much the same. You can think of it as `,` to jump to the next result, and `Shift + ,` to jump to the previous result.  \n  \n  \n`noremap \u003cC-s\u003e :w\u003cCR\u003e`\n\nMake the default keybind for saving in Vim also supported in Sublime.  \n  \n  \n`vnoremap \u003cTab\u003e \u003egv\nvnoremap \u003cS-Tab\u003e \u003cgv`\n\nI don't know all the technicalities of this one, but what it allows is for the repeated indentation and reverse indentation of a selection in visual mode, using `Tab` and `Shift + Tab`.\n\nThat's all I've got! Have fun customizing to make it your own ~\n"},{"title":"Git Reference: Keep it Simple. Common Workflows","date":"2019-09-03T19:28:34.000Z","slug":"git-reference-keep-it-simple-common-workflows","content":"\nAnywhere you see `\u003cremote\u003e`, you should probably use `origin`. More on origin vs upstream below.\n\n## Reference\n\n`git status` : display current branch and information on file changes\n\n`git branch` : view all local branches\n\n`git checkout \u003cbranch\u003e` : switch to the specified branch\n\n`git branch -d \u003cbranch\u003e` : delete a branch (may require `-D` to force if the branch has commits unique to it)\n\n`git checkout -b \u003cname\u003e` : create a new branch based on the current branch, specifying a name\n\n`git fetch` : download changes from remote\n\n`git merge \u003cremote\u003e/\u003cbranch\u003e` : merge another branch into current branch\n\n`git pull` : fetch and merge the remote of the current branch into the local current branch\n\n`git rebase \u003cbranch\u003e` : like merge, but move the current branch's unique commits to be the newest commits in the commit history\n\n`git push \u003cremote\u003e HEAD` : push current local branch to remote branch with the same name. If remote branch does not yet exist, requires `-u` flag to create it. If pushing to an existing branch after a rebase, `-f` flag to force will be required (be careful), as the commit history has been overwritten.\n\n`git diff` : view line additions and deletions for tracked modified files not yet added to staging\n\n`git diff --cached` : view line additions and deletions for files added to staging\n\n`git log` : view commit history with commit hashes\n\n`git reset` : remove all files from staging (implicit --soft)\n\n`git checkout -- \u003cfile or directory\u003e` : Undo changes made to the specified file(s) (tracked and unstaged files)\n\n`git reset --hard \u003ccommit-hash\u003e` or `git reset --hard \u003cbranch\u003e` : reset current branch to match a specific commit or latest commit of a specified branch.  \nExample:  \n`git reset --hard 151fb5a134912aacec63969f479dd59e5057ff22`  \nor `git reset --hard master`.\n\n`git reflog` : view history of executed git commands. Undo Git actions with `git reset --hard \u003chistory-hash\u003e` where history-hash is the hash shown in reflog of the state you want to go back to.\n\n## Resolve Merge Conflicts\n\n1.  `git status` to see files which contain conflicts\n2.  Open conflicting files in your editor and make desired changes, remembering to delete the lines added by Git containing `\u003e\u003e\u003e\u003e\u003e\u003e\u003e`, `=======`, `\u003c\u003c\u003c\u003c\u003c\u003c\u003c`.\n3.  `git add .` from top level directory of your git repo to add all files\n4.  `git merge --continue` to continue or `git merge --abort` at any time to cancel the merge\n\n## Reset my current branch to be exactly like remote master\n\n1.  `git fetch` : download changes from remote\n2.  `git reset --hard \u003cremote\u003e/master` : reset current branch to be identical to remote master branch\n\n## Origin vs Upstream?\n\nUpstream is only applicable in the context of GitHub Forks, as far as I know. There's a good explanation here: [Stack Overflow](https://stackoverflow.com/questions/9257533/what-is-the-difference-between-origin-and-upstream-on-github). You may want a workflow where you develop from your fork, get updates from the original repository, and push changes to your fork (perhaps to then open pull requests for the original repo). If that's the case, you want certain commands to specify upstream, and others origin:\n\n`git pull upstream master` (on local master) to update your clean local copy of the original repo as changes get merged to master.\n\nThen `git rebase master` or `git merge master` (on your feature branch) to update your feature branches.\n\n`git push -u origin HEAD` to push your feature branch to your own forked repo.\n"},{"title":"Multiple Inheritance in Python: Method Resolution Order (MRO)","date":"2019-08-30T16:08:56.000Z","slug":"multiple-inheritance-in-python-method-resolution-order-mro","content":"\n```python\nclass A:\n    def __init__(self):\n        print('A')\n\nclass B(A):\n    def __init__(self):\n        super().__init__()\n        print('B')\n\nclass C(A):\n    def __init__(self):\n        super().__init__()\n        print('C')\n\nclass D(B, C):\n    def __init__(self):\n        super().__init__()\n        print('D')\n\nd = D()\n```\n\nWhen class `D` is instantiated, what do you think will be the order of the print statements?\n\nPython's way of determining the order in which multiple inheritance is resolved is called the Method Resolution Order (MRO). The answer to the question is:\n\n```python\nA\nC\nB\nD\n```\n\nLets see why.\n\n```python\nclass D(B, C):\n    def __init__(self):\n        super().__init__()\n        print('D')\n```\n\nWe begin in class D, which inherits from both B and C. Here, Python resolves from right to left. What this means is that the first class listed takes precedence. If both class B and C defined a method, class B's version would be the one inherited by class D. Resolving right to left, `B \u003c- C`, B's definition of the method would overwrite C's.\n\nSince Python resolves the inheritance of class `C` first, we jump into `C.__init__`.\n\n```python\nclass C(A):\n    def __init__(self):\n        super().__init__()\n        print('C')\n```\n\nBefore even reaching our print statement, we get redirected to `A.__init__`. Once in class A, there's nothing left to inherit, so we reach our first print statement `print('A')`. After that, we go back up the chain that got us to A. Next we hit `print('C')`, then finally we return to class D.\n\n```python\nclass D(B, C):\n    def __init__(self):\n        super().__init__()\n        print('D')\n```\n\nWe're still not done with `super().__init()`. We've resolved class C, now we're onto B.\n\n```python\nclass B(A):\n    def __init__(self):\n        super().__init__()\n        print('B')\n```\n\nSince B inherits from class A, don't we go back there again? Python keeps track of the order of inheritance, and disregards duplicate entries. We have already visited class A during our inheritance journey, so Python will skip going there again altogether. This is where Method Resolution Order comes in. `__mro__` is an attribute that can be called on a class (not an instance). Lets see what it returns:\n\n```python\nprint(D.__mro__)\n# (\u003cclass '__main__.D'\u003e, \u003cclass '__main__.B'\u003e, \u003cclass '__main__.C'\u003e, \u003cclass '__main__.A'\u003e, \u003cclass 'object'\u003e)\n```\n\nLook at that, the order of our print statements was `A, C, B, D`. Python begins with the class 'object', and builds on it with each level of inheritance. `__mro__` and the order of our print statements are the same but reversed.\n\nFinishing our example, we skip going to class A inherited by B, since we already visited A when it was inherited by C. We hit `print('B')`, then finally return to class D and hit `print('D')`.\n"},{"title":"Understanding Promises in JavaScript","date":"2019-08-29T20:35:44.000Z","slug":"understanding-promises-in-javascript","content":"\nPromises are really confusing. There's a lot of keywords associated with promises and async JS:\n\n-   Promise\n-   resolve\n-   reject\n-   then\n-   catch\n-   async\n-   await\n\nFrom MDN:\n\n```javascript\nnew Promise(executor);\n```\n\n`executor`\n\n\u003e A function that is passed with the arguments resolve and reject. The executor function is executed immediately by the Promise implementation, passing resolve and reject functions...\n\nSo if we break this down further, the expected arguments look like this:\n\n```javascript\nnew Promise(function executor(resolve, reject));\n```\n\nWe define the `executor` function, which receives `resolve` and `reject` callback functions as arguments.\n\n```javascript\nnew Promise(function executor(resolve, reject) {\n  if (true) {  // Success\n    resolve('Resolved the promise');\n  } else {  // Error\n    reject('Rejected the promise');\n  }\n});\n```\n\nThe `executor` function doesn't have to be named, I'm just making my example explicit.\n\nOnce the promise has been resolved or rejected, that will trigger either a chained `then` or `catch` to be called.\n\n```javascript\nnew Promise(function(resolve, reject) {\n  if (true) {  // Success\n    resolve('Resolved');\n  } else {  // Error\n    reject('Rejected');\n  }\n})\n.then(function(result) {\n  console.log(result);  // 'Resolved'\n})\n.catch(function(error) {\n  console.log(error);  // 'Rejected'\n});\n```\n\nAn alternative syntax (that I think is more confusing), is to pass a second argument to `then`, which will handle `reject` in place of `catch`. I would not recommend this but it's good to know.\n\n```javascript\nnew Promise(function executor(resolve, reject) {\n  if (true) {  // Success\n    resolve('Resolved');\n  } else {  // Error\n    reject('Rejected');\n  }\n})\n.then(function(result) {\n  console.log(result);  // 'Resolved'\n}, function(error) {\n  console.log(error);  // 'Rejected'\n});\n```\n\nNow that we understand the general behavior of Promises, let's break down this example `sleep` function.\n\n```javascript\nfunction sleep(ms) {\n  return new Promise(function(resolve) {\n    setTimeout(function() {\n      resolve('Resolved Value');\n    }, ms);\n  })\n}\n\nasync function main() {\n  console.log('Before sleep');\n  const resolvedValue = await sleep(5000);  // 5 seconds\n  console.log('After sleep');\n  console.log(resolvedValue);  // 'Resolved Value'\n}\n\nmain();\n```\n\nNormally if we were to call `sleep` without `await`, there would be no 5 second pause between the two log statements. That's because our `sleep` function returns a promise, so we must wait for it to be resolved if we want our `main` function to be executed synchronously.\n\nIn order to use the `await` keyword, the surrounding function, `main`, must be given the `async` keyword.\n\n`setTimeout` is an asynchronous function, one of few in JS's built in library. However, `setTimeout`_ is not a Promise-based asynchronous function, it is callback-based_. In order to `await` for `setTimeout` to complete, we must wrap it in a promise, and `resolve` that promise inside the callback function we provide to `setTimeout`.\n\nHere's a shorthand version of the above using arrow functions.\n\n```javascript\nconst sleep = ms =\u003e new Promise(resolve =\u003e setTimeout(() =\u003e resolve('Resolved Value'), ms));\n\nasync function main() {\n  console.log('Before sleep');\n  const resolvedValue = await sleep(5000);  // 5 seconds\n  console.log('After sleep');\n  console.log(resolvedValue);  // 'Resolved Value'\n}\n\nmain();\n```\n\nPromises are confusing. If you don't understand them fully, don't worry about it. Check out other resources, and most importantly, play around with the code yourself.\n"},{"title":"Slate.js: Draft.js without the Bad Parts","date":"2019-08-28T15:37:27.000Z","slug":"slatejs-draftjs-without-the-bad-parts","content":"\nAnyone who has used Facebook's open source package, `Draft.js` knows that while it's a powerful tool for building rich text editors, the API docs are underdeveloped, and can be very difficult to understand. The editor I wrote this blog post in was made by me with `Slate.js`, and before I found that, I was struggling to learn how to make Draft.js do what I wanted it to do. I don't have the expertise to go too into detail about comparing Slate and Draft, but a lot of that is covered here in the readme of Slate: [Slate Principles](https://github.com/ianstormtaylor/slate#principles). Instead I'll tell you about my use case: what I wanted to build with Draft, the problems I ran into, and how Slate made the process easier for me.\n\nGiven that this is a programming blog, the most important feature to me is beautiful code snippets with syntax highlighting. Like so:\n\n```javascript\n// A JavaScript comment\nconst language = 'JavaScript';\nconsole.log(`This is definitely ${language}`);  // This is definitely JavaScript\n```\n\nI had `Prism.js` to handle the syntax highlighting.\n\nI needed my editor to...\n\n1.  Handle multi-line code blocks\n2.  Keep all those lines within the tags `\u003cpre\u003e\u003ccode\u003e ... \u003c/code\u003e\u003c/pre\u003e` (To comply with how Prism.js works)\n3.  Have a way to specify the syntax (via adding a css class to a `\u003ccode\u003e` tag: `language-javascript`)\n\nNot too many requirements. This seemed very doable in Draft, especially considering that the example on [draftjs.org](https://draftjs.org) features a Code Block styling option. If you click the code block toggle, make it a couple lines long, and inspect the page, you'll see that each line has it's own `\u003cpre\u003e` tag. Ah, that fails requirement #2 for me, but I'm sure I can customize mine to behave differently.\n\nAt the end of the day, I did just want a rich text editor, much like the one on Draft.js' home page, but with my customized code blocks. I found an npm package `react-rte`, which is pretty much a pre-built rich text editor built on Draft.js, with the ability to customize _certain_ things further (with this package, Draft was being abstracted away, and I could only customize parts that the creators of react-rte designated). Out of the box, react-rte did have multi-line code blocks contained in a single `\u003cpre\u003e` tag, and the ability to insert a soft line-break to stay inside a code block with Shift + Enter. Not bad, until you try to _**paste**_ a bunch of code in... which is the main way I would be inserting code into blog posts, pasting it from my real editor.\n\nSo how do you solve this problem?\n\nWhat would be needed is a special condition for code blocks. If the content block is a code block, insert another code line, without exiting that parent code block. _I'm sure this type of behavior would have been possible in Draft.js,_ but the trouble was figuring out _how_.\n\nThis is the main difference between Draft and Slate: Slate gives you tons of examples _with_ those examples being demonstrated on Slate's website, an excellent getting started walkthrough, and an API that actually makes sense.\n\nBecause of these offerings, my experience with Slate went something like this...\n\n1.  Read the Walkthrough (a very pleasant experience might I add)\n2.  Refer to examples... _\"Oh look, 'Rich Text' and 'Code Highlighting' are exactly what I want, I'll just look at the source code for these and combine them into my own!\"_\n3.  Complete customization of my editor, referring to Slate's API docs\n\nAnd there are many more examples I'll be pulling from. At the time of writing this post, my editor doesn't have support for images, but there's an example on Slate's site I'll be referring to.\n\nHappy custom editor building ~\n"}]},"__N_SSG":true},"page":"/blog","query":{},"buildId":"GUVWFM4qDg1OQBmqApV-Q","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>